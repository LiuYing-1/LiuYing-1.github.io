<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://liuying-1.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://liuying-1.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-08T14:47:54+00:00</updated><id>https://liuying-1.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Graduation</title><link href="https://liuying-1.github.io/blog/2024/graduation/" rel="alternate" type="text/html" title="Graduation"/><published>2024-06-28T10:15:00+00:00</published><updated>2024-06-28T10:15:00+00:00</updated><id>https://liuying-1.github.io/blog/2024/graduation</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/graduation/"><![CDATA[<p>I am thrilled to announce that I have successfully defended my master thesis and received my Master‚Äôs Degree in Computer Science from the Department of Computer Science (DIKU), University of Copenhagen.</p> <div class="row mt-3 mb-3"> <div class="col-sm mt-3 mt-md-0"> <img src="/assets/img/graduation-photo.jpg" alt="graduation-photo" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/7Ee4Raf.jpeg" alt="graduation-photo-2" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <p>The title of my thesis is ‚ÄúExploration of Self-Supervised Learning Methods for Longitudinal Image Analysis‚Äù, specifically focusing on the application of self-supervised learning methods, which are BYOL and SimSIAM, in medical image analysis for longitudinal studies (i.e., tumor progression) on lung cancer. The 3D ResNet model is first pre-trained on the LIDC-IDRI dataset, and then the model is tasked with predicting the tumor volume at the future timepoint of the same subject, on the Longitudinal 4D Lung dataset. The results show that the self-supervised learning methods cannot be used to train 3D ResNet to learn meaningful representations for longitudinal image analysis, and the learned representations are not significantly correlated with the actual tumor volume, verified by the linear probing task. This failure is attributed to the following reasons: 1. the volume featured by the LIDC-IDRI dataset (nodules) is with substatial differences from the Longitudinal 4D Lung dataset (tumors), 2. the current pre-processing pipeline does not isolate the lung region perfectly, 3. the model is not fine-tuned on the longitudinal downstream task, and 4. the invovled augmentations impair the model‚Äôs ability to learn precise tumor volume representations.</p> <div class="row mt-3 mb-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/16tSUKF.png" alt="2831691531627_.pic" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <p>I am grateful for the support and guidance from my supervisor, friends, and family, along the way. Thank you to everyone who has been a part of this journey with me. üéìüéâ</p> <p>Additionally, I am very excited to share the news that I am going to work as an AI engineer in a company, to embark on the next chapter of my life and look forward to new opportunities and challenges. üöÄ</p>]]></content><author><name></name></author><category term="study"/><category term="ucph"/><category term="fun"/><summary type="html"><![CDATA[Congratulations to my graduation from the DIKU, University of Copenhagen.]]></summary></entry><entry><title type="html">a post with tabs</title><link href="https://liuying-1.github.io/blog/2024/tabs/" rel="alternate" type="text/html" title="a post with tabs"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://liuying-1.github.io/blog/2024/tabs</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="73231f50-3d66-4daf-84f9-4eb758178d3d" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="73231f50-3d66-4daf-84f9-4eb758178d3d" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="98cd1290-758c-4843-b52e-4e4ac6176dd2" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="98cd1290-758c-4843-b52e-4e4ac6176dd2" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="6cc80c31-b914-423b-9771-ad9144f7f4eb" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="6cc80c31-b914-423b-9771-ad9144f7f4eb" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included tabs in a post could look like]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://liuying-1.github.io/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://liuying-1.github.io/blog/2024/typograms</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry><entry><title type="html">a post that can be cited</title><link href="https://liuying-1.github.io/blog/2024/post-citation/" rel="alternate" type="text/html" title="a post that can be cited"/><published>2024-04-28T15:06:00+00:00</published><updated>2024-04-28T15:06:00+00:00</updated><id>https://liuying-1.github.io/blog/2024/post-citation</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/post-citation/"><![CDATA[<p>This is an example post that can be cited. The content of the post ends here, while the citation information is automatically provided below. The only thing needed is for you to set the <code class="language-plaintext highlighter-rouge">citation</code> key in the front matter to <code class="language-plaintext highlighter-rouge">true</code>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="citation"/><summary type="html"><![CDATA[this is what a post that can be cited looks like]]></summary></entry><entry><title type="html">a post with pseudo code</title><link href="https://liuying-1.github.io/blog/2024/pseudocode/" rel="alternate" type="text/html" title="a post with pseudo code"/><published>2024-04-15T00:01:00+00:00</published><updated>2024-04-15T00:01:00+00:00</updated><id>https://liuying-1.github.io/blog/2024/pseudocode</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/pseudocode/"><![CDATA[<p>This is an example post with some pseudo code rendered by <a href="https://github.com/SaswatPadhi/pseudocode.js">pseudocode</a>. The example presented here is the same as the one in the <a href="https://saswat.padhi.me/pseudocode.js/">pseudocode.js</a> documentation, with only one simple but important change: everytime you would use <code class="language-plaintext highlighter-rouge">$</code>, you should use <code class="language-plaintext highlighter-rouge">$$</code> instead. Also, note that the <code class="language-plaintext highlighter-rouge">pseudocode</code> key in the front matter is set to <code class="language-plaintext highlighter-rouge">true</code> to enable the rendering of pseudo code. As an example, using this code:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">pseudocode
</span><span class="sb">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Generates:</p> <pre><code class="language-pseudocode">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included pseudo code could look like]]></summary></entry><entry><title type="html">Review of SwAV</title><link href="https://liuying-1.github.io/blog/2024/swav/" rel="alternate" type="text/html" title="Review of SwAV"/><published>2024-02-12T10:31:00+00:00</published><updated>2024-02-12T10:31:00+00:00</updated><id>https://liuying-1.github.io/blog/2024/swav</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/swav/"><![CDATA[]]></content><author><name></name></author><category term="study"/><category term="ucph"/><category term="ssl"/><summary type="html"><![CDATA[This is the learning of the paper SwAV.]]></summary></entry><entry><title type="html">Review of SimSiam</title><link href="https://liuying-1.github.io/blog/2024/simsiam/" rel="alternate" type="text/html" title="Review of SimSiam"/><published>2024-02-12T09:31:00+00:00</published><updated>2024-02-12T09:31:00+00:00</updated><id>https://liuying-1.github.io/blog/2024/simsiam</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/simsiam/"><![CDATA[]]></content><author><name></name></author><category term="study"/><category term="ucph"/><category term="ssl"/><summary type="html"><![CDATA[This is the learning of the paper SimSiam.]]></summary></entry><entry><title type="html">Extracts from BYOL</title><link href="https://liuying-1.github.io/blog/2024/byol/" rel="alternate" type="text/html" title="Extracts from BYOL"/><published>2024-02-11T08:00:00+00:00</published><updated>2024-02-11T08:00:00+00:00</updated><id>https://liuying-1.github.io/blog/2024/byol</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/byol/"><![CDATA[<p>BYOL is the abbr. of <u>Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning</u>.</p> <h3 id="cookbook-for-byol">Cookbook for BYOL</h3> <p>First of all, BYOL method probably the first one removes the clustering step, introduces a predictor and projector network, fefines the continuous targets as the output of a momentum network, renormalize each sample representation by its \(l_2\)-norm and leverage positive pairs. The predictor acts as a whitening operator preventing collapse, and momentum network can be applied only to the projector.</p> <p>It first introduced self-distillation as a means to avoid collapse. It usees two networks along with a predictor to map the outputs of one network to the other. The network predicting the output is called the online or student network while the network producing the target is called the target or teacher network. Each network receives a different view of the same image formed by image transformations including random resizing, cropping, color jittering, and brightness alterations. The student network is updated throughout training using gradient descent. The teacher network is updated with an exponential moving average (EMA) updates of the weights of the online network. The slow updates induced by exponential moving average creates an asymmetry that is crucial to BYOL‚Äôs success.</p> <h3 id="original-paper">Original Paper</h3> <p>Please check the original paper here <a href="https://arxiv.org/abs/2006.07733">BYOL</a>.</p> <h4 id="abstract">Abstract</h4> <ul> <li><strong>BYOL</strong>, a <strong>new</strong> apporach to <strong>self-supervised learning</strong>.</li> <li>BYOL relies on two neural networks, referred to as the <strong>online</strong> network and the <strong>target</strong> network, that <strong>interact</strong> and <strong>learn from each other</strong>.</li> <li>From <strong>an augmented view of an image</strong>, we train the <strong>online network to predict the target network representation of the same image under a different augmented view</strong>.</li> <li>At the same time, we <strong>update the target network with a slow-moving average of the online network</strong>.</li> <li>(Back then), while state-of-the-art methods <strong>rely on negative pairs</strong>, BYOL achieves a new state of the art <strong>without them</strong>.</li> </ul> <hr/> <p>Online first updates, updates of target come from online by EMA.</p> <p>Without negative pairs can be competative as well.</p> <p>Train the online to predict the target network representation.</p> <hr/> <h4 id="introduction">Introduction</h4> <ul> <li>(Back then,) state-of-the-art <strong>contrastive methods</strong> are trained by <strong>reducing the distance between representations of different augmented views of the same image (‚Äòpositive pairs‚Äô)</strong>, and <strong>increasing the distance between representations of augmented views from different images (‚Äònegative pairs‚Äô)</strong>.</li> <li>These methods need <strong>careful treatment of negative pairs</strong> by either <strong>relying on large batch sizes</strong>, <strong>memory banks</strong> or <strong>customized mining strategies</strong> to retrieve the negative pairs.</li> <li>In addition, their performance <strong>critically</strong> depends on the <strong>choice of image augmentations</strong>.</li> </ul> <hr/> <p>BYOL can overcome the previous shortages from the previous methods, which are: <strong>no need negative pairs</strong>, <strong>careful treatment of negative pairs</strong>, <strong>choice of hyper-parameters</strong>, and <strong>choice of augmentations</strong>.</p> <hr/> <ul> <li>BYOL achieves higher performance than state-of-the-art contrastive methods <strong>without using negative pairs</strong>.</li> <li>It <strong>iteratively</strong> <strong>bootstraps the outputs of a network to serve as targets for an enhanced representation</strong>.</li> <li>BYOL is <strong>more robust</strong> to the <strong>choice of image augmentations</strong> than contrastive methods; we suspect that <strong>not relying on negative pairs</strong> is one of the leading reasons for its <strong>improved robustness</strong>.</li> <li>We propose to <strong>directly bootstrap the representations</strong>. ==&gt; Different from previous methods.</li> <li>In particular, <strong>BYOL uses two neural networks, referred to as online and target networks, that interatct and learn from each other.</strong></li> <li>Starting from <strong>an augmented view of an image</strong>, BYOL <strong>trains its online network</strong> to <strong>predict the target network‚Äôs representation</strong> of <strong>another augmented view</strong> of the <strong>same image</strong>.</li> <li>While this objective <strong>admits collapsed solutions</strong>, e.g., <strong>outputting the same vector for all images</strong>, we empirically show that <strong>BYOL does not converage to such solutions</strong>.</li> <li>We hypothesize that the <strong>combination</strong> of (i) the <strong>addition of a predictor to the online network</strong> and (ii) the <strong>use of a slow-moving average of the online parameters as the target network</strong> encourages <strong>encoding more and more information within the online projection</strong> and <strong>avoids collapsed solutions</strong>.</li> </ul> <hr/> <ul> <li>BYOL achieves state-of-the-art results under the <strong>linear evaluation protocol on ImageNet without using negative pairs</strong>.</li> <li>Our learned representation outperforms the state of the art on semi-supervised and transfer benchmarks.</li> <li>BYOL is <strong>more resilient</strong> to <strong>changes in the batch size</strong> and <strong>in the set of image augmentations</strong> compared to its contrastive counterparts.</li> <li>In particular, BYOL sufferes a much smaller performance drop than SimCLR, a strong contrastive basline, when only using random crops as image augmentations.</li> </ul> <h4 id="related-work">Related work</h4> <ul> <li>Most <strong>unsupervised methods for representation learning</strong> can be categorized as either <strong>generative</strong> or <strong>discriminative</strong>.</li> <li><strong>Generative approaches to representation learning</strong> build <strong>a distribution over data and latent embedding</strong> and <strong>use the learned embeddings as image representations</strong>.</li> <li>Many of these apporaches <strong>rely either on auto-encoding of images</strong> or on <strong>adversarial learning</strong>, jointly modelling data and representation.</li> <li>Generative methods typically operate <strong>directly in pixel space</strong>.</li> <li>This however is <strong>computationally expensive</strong>, and the <strong>high level of detail required for image generation</strong> may <strong>not be necessary</strong> for representation learning.</li> </ul> <hr/> <p>The <strong>intro</strong> and <strong>drawbacks</strong> of generative methods.</p> <hr/> <ul> <li>Among <strong>discriminative</strong> methods, <strong>contrastive methods</strong> currently achieves state-of-the-art performance in self-supervised learning.</li> <li><strong>Contrastive methods often</strong> require comparing each example with many other examples to work well, <strong>prompting the question of whether using negative pairs is necessary</strong>.</li> </ul> <hr/> <p><strong>Contrastive methods</strong> belongs to <strong>discriminative methods</strong>, and are best, while <strong>prompting the question of negative pairs</strong>.</p> <hr/> <ul> <li><strong>DeepCluster partially answers this question</strong>.</li> <li>While <strong>avoiding the use of negative pairs</strong>, this requires <strong>a costly clustering phase and specific precautions to avoid collapsing to trivial solutions</strong>.</li> </ul> <hr/> <p>Might <strong>not necessary</strong> for the use of <strong>negative pairs</strong> if under suitable settings.</p> <hr/> <ul> <li>Some self-supervised methods are <strong>not contrastive but rely on using auxiliary handcrafted prediction tasks</strong> to learn their representation.</li> <li>Yet, even with suitable architectures, these methods are being <strong>outperformed by contrastive methods</strong>.</li> </ul> <hr/> <p>Some other methods might <strong>better</strong> than contrastive methods.</p> <hr/> <ul> <li>Our approach <strong>has some similarities</strong> with <em>Predictions of Bootstrapped Latents</em> (PBL).</li> <li>PBL <strong>jointly trains the agent‚Äôs history representation</strong> and <strong>an encoding of future observations</strong>.</li> <li><strong>Unlike PBL</strong>, <strong>BYOL uses a slow-moving average of its representation to provide its targets, and does not require a second network.</strong></li> </ul> <hr/> <p>BYOL stems from PBL but unlike PBL.</p> <hr/> <ul> <li>The <strong>idea of using a slow-moving average target network to produce stable targets</strong> for the online network was inspired by deep RL.</li> <li> <p>Target networks stabilize the bootstrapping updates provided by the Bellman equation, <strong>making them appealing to stabilise the bootstrap mechanism in BYOL</strong>.</p> </li> <li>While <strong>most RL methods use fixed target networks</strong>, BYOL uses <strong>a weighted moving average of previous networks in order to provide smoother changes in the target representation</strong>.</li> </ul> <hr/> <p>The origin of the moving weights.</p> <hr/> <ul> <li>In the semi-supervised ‚Ä¶. Among these methods, mean teacher also uses a slow-moving average network, called teacher, to produce targets for an online network, called student.</li> <li><strong>In contrast, BYOL introduces an additional predictor on top of the online network, which prevents collapse.</strong></li> </ul> <hr/> <p>The use of predictor.</p> <hr/> <ul> <li>Finally, in self-supervised learning, MoCo uses a slow-moving average network (momentum encoder) to maintain consistent representations of negative pairs drawn from a memory bank.</li> <li>Instead, <strong>BYOL uses a moving average network to produce prediction targets</strong> as a means of stabilizing the bootstrap step.</li> </ul> <h4 id="method">Method</h4> <ul> <li>Many such approaches <strong>cast the prediction problem directly in representation space</strong>: the <strong>representation of an augmented view of an image</strong> should be <strong>predictive of the representaion of another augmented view of the same image</strong>.</li> <li>However, <strong>predicting directly in represntation space</strong> can lead to <strong>collapsed representations</strong>.</li> <li>Contrastive methods circumvent this problem by reformulating the prediction problem into one of discrimination. ‚Ä¶ and the <strong>representations of augmented views of different images</strong>.</li> <li>In this work, we thus <strong>tasked ourselves to find out whether these negative examples are indispensable to prevent collapsing while preserving high performance.</strong></li> </ul> <hr/> <p>cross-view ËÉΩÔºöÂõæÂÉèÁöÑÂ¢ûÂº∫ËßÜÂõæÁöÑË°®ÂæÅËÉΩÈ¢ÑÊµãÂêå‰∏ÄÂõæÁöÑÂè¶‰∏Ä‰∏™Â¢ûÂº∫ÁöÑË°®ÂæÅÔºå‰ΩÜÊòØ‰ª£‰ª∑ÊòØÊÄªËÉΩÈ¢ÑÊµãËá™Â∑±Êù•ÂØºËá¥ trivial solutionsÔºàÂùçÂ°åÔºâ„ÄÇÊâÄ‰ª•Êàë‰ª¨ÁöÑÊñπÊ≥ïÊù•È™åËØÅËÉΩÂê¶‰øùÊåÅÈ´òÊÄßËÉΩÁöÑÂêåÊó∂ÔºåË¥üÊ†∑Êú¨ÁöÑÂ≠òÂú®ÊòØÂê¶ÂøÖÈ°ª„ÄÇ</p> <hr/> <ul> <li>To <strong>prevent collapse, a straightforward solution is to use a fixed randomly initialized network</strong> to poduce the <strong>targets</strong> for our predictions.</li> <li>While avoidng collapse, it <strong>empircally does not result in very good representations</strong>.</li> <li>It is interesting to note that the <strong>representation obtained using this procedure</strong> can already be <strong>much better than the initial fixed represntation</strong>.</li> <li>This experimental finding is the <strong>core motivation</strong> for BYOL: <strong>from a given representation, referred to as target, we can train a new, potentially enhanced representation, referred to as online, by predicting the target representation.</strong></li> <li>We can expect to <strong>build a sequence of representations of increasing quality by iterating this procedure</strong>, <strong>using subsequent online networks as new target networks for further training.</strong></li> <li>In practice, BYOL <strong>generalizes this bootstrapping procedure</strong> by <strong>iteratively refining its representation</strong>, but <strong>using a slowly moving exponential average of the online network</strong> as the target network <strong>instead of fixed checkpoints</strong>.</li> </ul> <hr/> <p>ÁªèÈ™åËßâÂæó fixed ‰∏çË°åÔºå‰ΩÜÊòØÂ∑≤ÁªèÊïàÊûú‰∏çÈîô‰∫ÜÔºåÊâÄ‰ª•Êàë‰ª¨Âü∫‰∫éÊ≠§ËÆæËÆ°‰∫ÜÊñ∞ÁöÑ„ÄÇ‰ªé‰∏Ä‰∏™ÁªôÂÆöÁöÑË°®ÂæÅÔºàtargetÔºâËÆ≠ÁªÉ‰∏Ä‰∏™Êñ∞ÁöÑÂä†Âº∫ÁöÑË°®ÂæÅÔºàonlineÔºâÊù•È¢ÑÊµã target ÁöÑË°®ÂæÅ„ÄÇ</p> <hr/> <h5 id="description-of-byol">Description of BYOL</h5> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/7aUmfsC.png" alt="image-20230919201623320" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <div class="caption"> Figure 1. BYOL's architectures </div> <ul> <li> <p>BYOL‚Äôs <strong>goal</strong> is to <strong>learn a representation</strong> \(y_\theta\) <strong>which can then be used for downstream tasks</strong>. ==&gt; <strong>representation</strong>.</p> </li> <li> <p>BYOL uses <strong>two neural networks</strong> to learn: the <strong>online</strong> and <strong>target networks</strong>.</p> </li> <li> <p>The <strong>online network is defined by a set of weights</strong> \(\theta\) and is comprised of <strong>three stages</strong>: an <em>encoder</em> \(f_\theta\), a projector \(g_\theta\) and a predictor \(q_\theta\)‚Äã.</p> </li> <li> <p>The <strong>target network has the same architecture as the online network</strong>, but <strong>uses a different set of weights</strong> \(\xi\).</p> </li> <li> <p>The <strong>target</strong> network provides the <strong>regression targets to train the online network</strong>, and its parameters \(\xi\) are an <strong>exponential moving average</strong> of the <strong>online</strong> parameters \(\theta\).</p> </li> <li> <p>Given a <strong>target decay rate</strong> \(\tau\in [0, 1]\)‚Äã, after each training step we perform the following update,</p> \[\xi \leftarrow \tau\xi + (1-\tau)\theta.\] </li> </ul> <hr/> <p>Online: encoder \(encoder(f_\theta) + prejector(g_\theta) + predictor(q_\theta)\), target has the same architecture but with different parameters comes from the above mentioned equation based on online.</p> <hr/> <ul> <li> <p>Given <strong>a set of images</strong> \(D\), an <strong>image</strong> \(x\sim D\) sampled uniformly from \(D\), and <strong>two distributions of image augmentations</strong> \(\mathcal{T}\) and \(\mathcal{T'}\), BYOL <strong>produces two augmented views</strong> \(v \triangleq t(x)\) and \(v'\triangleq t'(x)\) from \(x\) by <strong>applying respectively image augmentations</strong> \(t \sim \mathcal{T}\) and \(t' \sim \mathcal{T'}\). ==&gt; ‰ªé‰∏§‰∏™Áõ∏ÂêåÊµÅÁ®ãÁöÑÂ¢ûÂº∫Á≠ñÁï•‰∏äÈöèÊú∫ÈÄâ‰∏§Â•óÔºåÂõ†‰∏∫ÂèÇÊï∞Â§ßÊ¶ÇÁéá‰∏çÂêåÔºåÊâÄ‰ª•‰∏§Â•óÊµÅÁ®ãÁöÑÂèÇÊï∞‰∏çÂêåÔºåÊâÄ‰ª•ÊòØ‰∏§‰∏™‰∏çÂêåÁöÑ view„ÄÇ</p> </li> <li> <p>From the <strong>first augmented view</strong> \(v\), the <strong>online network outputs</strong> a <em>representation</em> \(y_\theta \triangleq f_\theta(v)\) and a <strong>projection</strong> \(z_\theta\triangleq g_\theta(y)\).</p> </li> <li> <p>The <strong>target</strong> network outputs \(y'_\xi \triangleq f_\xi(v')\) and the <em>target projection</em> \(z'_\xi \triangleq g_\xi(y')\) from the <strong>second augmented view</strong> \(v'\)‚Äã.</p> </li> <li> <p>We then output a <strong>prediction</strong> \(q_\theta(z_\theta)\) of \(z'_\xi\) and \(l_2\)-normalize both \(q_\theta(z_\theta)\) and \(z'_\xi\)‚Äã to</p> \[\overline{q_\theta}(z_\theta) \triangleq q_\theta(z_\theta)/\vert\vert q_\theta(z_\theta)\vert\vert_2\] <p>and</p> \[\overline{z'_\xi}/\vert\vert z'_\xi\vert\vert_2^2.\] </li> <li> <p>Note that this <strong>predictor is only applied to the online branch</strong>, making the <strong>architecture asymmetric between the online and target pipeline</strong>.</p> </li> <li> <p>Finally we dine the following mean squared error between the normalized predictions and target projections,</p> \[\mathcal{L}_{\theta, \xi} \triangleq \vert\vert{\overline{q_\theta}(z_\theta) - \overline{z'}_\xi}\vert\vert_2^2 = 2 - 2\cdot \frac{&lt;q_\theta(z_\theta), z'_\xi&gt;}{\vert\vert q_\theta(z_\theta)\vert\vert_2 \cdot \vert\vert z'_\xi\vert\vert_2}.\] </li> <li> <p>We <strong>symmetrize the loss above</strong> by separaetely feeding \(v'\) to the online network and \(v\) to the target network to compute the other one. ==&gt; ÂØπÁß∞ÁöÑÊç¢‰∏Ä‰∏ã‰∏§‰∏™ÁΩëÁªúÁöÑ viewÔºåÁÑ∂ÂêéÂ∞Ü‰∏§‰∏™Áõ∏Âä†ÂΩ¢ÊàêÊúÄÁªàÁöÑ loss„ÄÇ</p> </li> <li> <p>At <strong>each training step</strong>, we perform a stochastic optimization step to minimize</p> \[\mathcal{L}_{\theta, \xi}^{\text{BYOL}} = \mathcal{L}_{\theta, \xi} + \widetilde{\mathcal{L}}_{\theta, \xi}\] <p>with respect to \(\theta\) only, but not \(\xi\).</p> \[\theta \leftarrow \text{optimizer}(\theta, \nabla_\theta\mathcal{L}_{\theta, \xi}^{\text{BYOL}}, \eta),\\ \xi \leftarrow \tau\xi + (1-\tau)\theta\] <p>where optimizer is an optimzer and \(\eta\)‚Äã is a learning rate.</p> </li> <li> <p>At the end of training, we <strong>only keep the encoder</strong> $f_{\theta}$.</p> </li> </ul> <h5 id="implementation-details">Implementation details</h5> <ul> <li>Image augmentations: <ul> <li>BYOL uses the same set of image augmentations as in SimCLR.</li> <li>First a <strong>random patch of the image</strong> is selected and <strong>resized</strong> to \(224\times 224\)‚Äã with a random <strong>horizontal</strong> flip, followed by a <strong>color distrotion</strong>, consisting of a <strong>random sequence of brightness, contrast, saturation, hue adjustments, and an optional grayscale conversion</strong>. Finally, <strong>Gaussian blur</strong> and <strong>solarization</strong> are applied to the <strong>patches</strong>.</li> </ul> </li> <li><strong>Architecture</strong> <ul> <li><strong>ResNet</strong>-50 as our base parametric <strong>encoders</strong> \(f_\theta\) and \(f_\xi\)</li> <li>The <strong>representation</strong> $y$ <strong>corresopnds to the output of the final average pooling layer</strong>, which has a feature dimension of \(2048\).</li> <li>Contrary to SimCLR, the <strong>output</strong> of this MLP is <strong>not batch normalized</strong>. The <strong>predictor</strong> \(q_\theta\) uses the <strong>same</strong> <strong>architecture</strong> as \(g_\theta\)‚Äã.</li> </ul> </li> <li><strong>Optimization</strong> <ul> <li><strong>LARS</strong> <strong>optimizer</strong> with a <strong>cosine decay learning rate schedule</strong>, <strong>without restarts</strong>, over 1000 epochs, with a <strong>warm-up period of 10 epochs</strong>.</li> <li>the <strong>base learning rate</strong> to \(0.2\), scaled linearly with the batch size (Learning rate = \(0.2 \times \text{BatchSize}/256\))</li> <li>A global weight decay parameter of \(1.5\cdot 10^{-6}\) while excluding the biases and batch normalization parameters from both LARS adaptation and weight decay.</li> <li>A <strong>batch size of 4096</strong></li> </ul> </li> </ul>]]></content><author><name></name></author><category term="study"/><category term="ucph"/><category term="ssl"/><summary type="html"><![CDATA[Review of the paper BYOL and to extract the main points]]></summary></entry><entry><title type="html">Cookbook Reading - 1</title><link href="https://liuying-1.github.io/blog/2024/cookbook-1/" rel="alternate" type="text/html" title="Cookbook Reading - 1"/><published>2024-01-30T08:00:00+00:00</published><updated>2024-01-30T08:00:00+00:00</updated><id>https://liuying-1.github.io/blog/2024/cookbook-1</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/cookbook-1/"><![CDATA[<p>All the following text are stemmed from the source book, please refer to the original copy - <em><a href="https://arxiv.org/pdf/2304.12210.pdf">A Cookbook of Self-Supervised Learning</a></em>. Additionally, there will be a large amount of Chinese translations on it since it will be used for me to recall something, sorry in advance.</p> <h4 id="what-is-self-supervised-learning-and-why-bother">What is Self-Supervised Learning and Why Bother?</h4> <p>Ëá™ÁõëÁù£Â≠¶‰π†Ôºå‰πüË¢´Áß∞‰∏∫ the dark matter of intelligence„ÄÇ<u>ÂÆÉÊòØ‰∏Ä‰∏™ÊèêÂçáÊú∫Âô®Â≠¶‰π†ÁöÑÂ∫∑Â∫ÑÂ§ßÈÅì„ÄÇ</u>‰∏éÁõëÁù£Â≠¶‰π†‰∏ç‰∏ÄÊ†∑ÔºåÁõëÁù£Â≠¶‰π†ÂèóÂà∂‰∫éÊúâÊ†áÁ≠æÊï∞ÊçÆÁöÑÊï∞ÈáèÔºåËÄå<u>Ëá™ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïËÉΩÂ§ü‰ªéÂ§ßÈáèÊ≤°ÊúâÊ†áÁ≠æÁöÑÊï∞ÊçÆÈáåÈù¢ËøõË°åÂ≠¶‰π†</u>„ÄÇËá™ÁõëÁù£Â≠¶‰π†ÊòØÊ∑±Â∫¶Â≠¶‰π†Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÈ¢ÜÂüüÂèñÂæóÊàêÂäüÁöÑÂü∫Á°ÄÔºåÂÆÉÊé®Âä®‰∫Ü‰ªéËá™Âä®Êú∫Âô®ÁøªËØëÂà∞Âú®Êó†Ê†áËÆ∞ÊñáÊú¨ÁöÑÁΩëÁªúËßÑÊ®°ËØ≠ÊñôÂ∫ì‰∏äËÆ≠ÁªÉÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂèëÂ±ï„ÄÇÂú®ËÆ°ÁÆóÊú∫ËßÜËßâÈáåÈù¢ÔºåSSLÈÄöËøáÂú®10‰∫øÂº†ÂõæÂÉè‰∏äËÆ≠ÁªÉÁöÑSEERÁ≠âÊ®°ÂûãÔºåÂ∞Ü<u>Êï∞ÊçÆËßÑÊ®°Êé®Âêë‰∫ÜÊñ∞ÁöÑÊûÅÈôê</u>„ÄÇ‰∏Ä‰∫õÈíàÂØπËÆ°ÁÆóÊú∫Êï∞ÊçÆÁöÑSSLÊñπÊ≥ïÔºåÂç≥‰ΩøÂú®‰∏Ä‰∫õÁ´û‰∫âÁõ∏ÂØπÊøÄÁÉàÁöÑBenchmarks‰∏äÔºàe.g., ImageNetÔºâ<u>Â∑≤ÁªèËÉΩÂ§üÂíå‰∏Ä‰∫õÂú®ÊúâÊï∞ÊçÆÊ†áÁ≠æÁöÑËÆ≠ÁªÉÁöÑÁõëÁù£Â≠¶‰π†‰∏äÂæóÂà∞ÁöÑÊ®°ÂûãÁõ∏Â™≤ÁæéÁîöËá≥Êõ¥Â•Ω</u>„ÄÇSSL‰πüÂ∑≤ÁªèË¢´ÊàêÂäüËøêÁî®Âú®<u>ÂêÑ‰∏™Ê®°ÊÄÅÊï∞ÊçÆ</u>‰∏äÔºåÊØîÂ¶ÇËßÜÈ¢ëÔºåÈü≥È¢ëÔºåÂíå‰∏Ä‰∫õÊó∂Èó¥Â∫èÂàó„ÄÇ</p> <p>Ëá™ÁõëÁù£Â≠¶‰π†Ê†πÊçÆ‰ΩçÊ†áÁ≠æÁöÑËæìÂÖ•<u>ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™ËæÖÂä©‰ªªÂä°Êù•‰∫ßÂá∫descriptive and intelligibleÁöÑÁâπÂæÅ</u>„ÄÇÂú®Ëá™ÁÑ∂ËØ≠Ë®Ä‰∏≠Ôºå‰∏Ä‰∏™Â∏∏ËßÅÁöÑSSLÁöÑÁõÆÊ†áÂ∞±ÊòØÂéªÈÅÆ‰ΩèÔºàmaskÔºâ‰∏Ä‰∏™ÊñáÊú¨‰∏≠ÁöÑÂçïËØçÔºåÁÑ∂ÂêéÈ¢ÑÊµãÂë®Âõ¥ÁöÑÂçïËØç„ÄÇËøôÁßçÈ¢ÑÊµã‰∏Ä‰∏™ËØçÂë®Âõ¥ÁöÑ‰∏ä‰∏ãÊñáÁöÑÁõÆÊ†áÈºìÂä±‰∫ÜÊ®°Âûã‰∏ç‰æùËµñ‰ªª‰ΩïÊ†áÁ≠æ‰πüËÉΩÂéªÊçïÊçâÊñáÊú¨‰∏≠ËØçÊ±á‰∏≠ÁöÑÂÖ≥Á≥ª„ÄÇÂêåÊ†∑ÁöÑÁªèËøáSSLÊ®°ÂûãÂ≠¶Âà∞ÁöÑË°®ÂæÅ‰πüËÉΩË¢´Áî®‰Ωú‰∏ÄÁ≥ªÂàó‰∏ãÊ∏∏‰ªªÂä°‰∏äÔºåÊØîÂ¶Ç‰∏çÂêåËØ≠Ë®ÄÈó¥ÁöÑÊñáÊú¨ÁøªËØëÔºåÊÄªÁªìÔºåÁîöËá≥‰∫ßÁîüÊñáÊú¨ÔºåÂΩìÁÑ∂‰πüËøòÊúâ‰∏Ä‰∫õÂà´ÁöÑ„ÄÇÂú®CV‰∏≠Ôºå<strong>MAE</strong>Êàñ<strong>BYOL</strong>Ëøô‰∫õÊñπÊ≥ï‰πüÂ≠òÂú®Áõ∏‰ººÁöÑÁõÆÊ†áÔºåÈÄöËøáÂ≠¶‰π†Êù•È¢ÑÊµã‰∏Ä‰∏™ÂõæÂÉèË¢´ÈÅÆ‰ΩèÁöÑpatchÊàñËÄÖÂÖ∂Ë°®ÂæÅ„ÄÇ‰πüÊúâÂà´ÁöÑSSLÁõÆÊ†áÔºåÈÄöËøáÊ∑ªÂä†È¢úËâ≤ÊàñËÄÖË£ÅÂâ™ÂõæÁâáÊù•ÂΩ¢ÊàêÂêå‰∏Ä‰∏™ÂõæÁâáÁöÑ‰∏§‰∏™‰∏çÂêåËßÜËßíÔºåÁÑ∂ÂêéÈºìÂä±Ê®°ÂûãËÉΩÂ≠¶Âà∞Êò†Â∞ÑÂà∞Áõ∏‰ººË°®ÂæÅÁöÑËÉΩÂäõ„ÄÇ</p> <p>Êúâ‰∫ÜËÉΩÂäõÊù•Âú®Â§ßÈáèÁöÑÊú™Ê†áÁ≠æÊï∞ÊçÆ‰∏äËøõË°åËÆ≠ÁªÉÔºåÂ∏¶Êù•‰∫ÜÂæàÂ§öÂ•ΩÂ§Ñ„ÄÇ‰º†ÁªüÁöÑÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïÈÄöÂ∏∏ÊòØÊ†πÊçÆÁé∞ÊúâÁöÑÊúâÊ†áÁ≠æÊï∞ÊçÆÂØπÂ∑≤Áü•ÁöÑÁâπÂÆö‰ªªÂä°ËøõË°åËÆ≠ÁªÉÔºàÂÖàÈ™åÁöÑÔºâÔºåËÄå <u>SSL ÂàôÊòØÂ≠¶‰π†ÂØπËÆ∏Â§ö‰ªªÂä°ÈÉΩÊúâÁî®ÁöÑÈÄöÁî®Ë°®ÂæÅ</u>„ÄÇ<u>SSL Âú®ÂåªÂ≠¶Á≠âÈ¢ÜÂüüÂ∞§ÂÖ∂ÊúâÁî®</u>ÔºåÂõ†‰∏∫Âú®Ëøô‰∫õÈ¢ÜÂüü‰∏≠ÔºåÊ†áÁ≠æÁöÑÊàêÊú¨ÂæàÈ´òÔºåÊàñËÄÖÊó†Ê≥ï‰∫ãÂÖàÁü•ÈÅìÂÖ∑‰ΩìÁöÑ‰ªªÂä°„ÄÇËøòÊúâËØÅÊçÆË°®ÊòéÔºåSSL Ê®°ÂûãÂèØ‰ª•Â≠¶‰π†Âà∞ÂØπÂØπÊäóÊÄßÁ§∫‰æãÔºà<u>adversarial examples</u>Ôºâ„ÄÅÊ†áÁ≠æÊçüÂùèÔºà<u>label corruption</u>ÔºâÂíåËæìÂÖ•Êâ∞Âä®Ôºà<u>input perturbations</u>ÔºâÊõ¥Á®≥ÂÅ•Ôºà<u>robust</u>ÔºâÁöÑË°®ÂæÅÔºåËÄå‰∏î‰∏éÊúâÁõëÁù£ÁöÑÊ®°ÂûãÁõ∏ÊØîÊõ¥ÂÖ¨Âπ≥„ÄÇÂõ†Ê≠§ÔºåSSLÊòØ‰∏Ä‰∏™Ë∂äÊù•Ë∂äÂèóÂÖ≥Ê≥®ÁöÑÈ¢ÜÂüü„ÄÇÁÑ∂ËÄåÔºåÂíåÂÅöÈ•≠ÂæàÂÉèÔºåËÆ≠ÁªÉSSLÊñπÊ≥ïÊòØ‰∏Ä‰∏™Èó®ÊßõÂæàÈ´òÁöÑÂæÆÂ¶ôËâ∫ÊúØ„ÄÇ</p> <h5 id="why-a-cookbook-for-self-supervised-learning">Why a Cookbook for Self-Supervised Learning?</h5> <p>ËôΩÁÑ∂ SSL ÁöÑËÆ∏Â§öÁªÑÊàêÈÉ®ÂàÜÈÉΩ‰∏∫Á†îÁ©∂‰∫∫ÂëòÊâÄÁÜüÊÇâÔºå‰ΩÜË¶ÅÊàêÂäüËÆ≠ÁªÉ SSL ÊñπÊ≥ïÔºåÂç¥ÈúÄË¶Å‰ªé<u>ÂÄüÂè£‰ªªÂä°Âà∞ËÆ≠ÁªÉË∂ÖÂèÇÊï∞</u>Á≠â‰∏ÄÁ≥ªÂàó‰ª§‰∫∫ÁúºËä±Áº≠‰π±ÁöÑÈÄâÊã©„ÄÇSSLÁ†îÁ©∂Êúâ‰∏Ä‰∏™È´òÁöÑÈó®ÊßõÔºå‰∏ÄÊòØÂõ†‰∏∫<u>ËÆ°ÁÆóÊàêÊú¨</u>Ôºå‰∫åÊòØ<u>Ê≤°ÊúâÂÆåÂÖ®ÈÄèÊòéÁöÑËÆ∫Êñá</u>ËØ¶ÁªÜËÆ≤Ëø∞ÂÖ∂‰∏≠ËÉΩÂ§üÂÖÖÂàÜÂèëÊå•SSLÁöÑÊΩúËÉΩÁöÑÂ§çÊùÇÁöÑÂÆûÁé∞ÊñπÊ≥ïÔºå‰∏âÊòØ<u>Áº∫‰πèSSLÁªü‰∏ÄÁöÑËØçÊ±áÂíåÁêÜËÆ∫ËßÇÁÇπ</u>„ÄÇÂõ†‰∏∫SSL‰ªé‰º†ÁªüÁöÑreconstruction-basedÊó†ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïÔºàe.g.Ôºådenoising variational autoencodersÔºâÂª∫Á´ã‰∫Ü‰∏ÄÂ•óÁã¨ÁâπÁöÑËåÉÂºèÔºåÊàë‰ª¨Âú®Áªü‰∏ÄËßÜËßí‰∏ãÁêÜËß£ SSL ÁöÑËØçÊ±áÊòØÊúâÈôêÁöÑ„ÄÇ‰∫ãÂÆû‰∏äÔºåÂú®‰∏Ä‰∏™Âçï‰∏ÄËßÜËßí‰∏ãÁªü‰∏ÄSSLÊñπÊ≥ïÂú®2021‰πü‰ªÖ‰ªÖÊâçÂºÄÂßãÂá∫Áé∞„ÄÇÂ¶ÇÊûúÊ≤°Êúâ‰∏Ä‰∏™ÂÖ±ÂêåÁöÑÂü∫Á°ÄÊù•ÊèèËø∞ SSL ÊñπÊ≥ïÁöÑ‰∏çÂêåÁªÑÊàêÈÉ®ÂàÜÔºåÁ†îÁ©∂‰∫∫ÂëòÂú®ÂºÄÂßãÁ†îÁ©∂ SSL ÊñπÊ≥ïÊó∂Â∞±‰ºöÈù¢‰∏¥Êõ¥Â§ßÁöÑÊåëÊàò„ÄÇÂêåÊó∂ÔºåSSLÁ†îÁ©∂‰πüÊÄ•ÈúÄÊñ∞ÁöÑÁ†îÁ©∂‰∫∫ÂëòÔºåÂõ†‰∏∫SSLÁé∞Âú®Â∑≤ÁªèÈÅçÂ∏ÉÊàë‰ª¨ÁöÑÁîüÊ¥ª‰∫Ü„ÄÇÁÑ∂ËÄåÔºåÂÖ≥‰∫é SSL ÁöÑ<u>ÈÄöÁî®ÊÄß‰øùËØÅ„ÄÅÂÖ¨Âπ≥ÊÄßÂ±ûÊÄß‰ª•ÂèäÂØπÂØπÊäóÊÄßÊîªÂáª</u>ÁîöËá≥<u>Ëá™ÁÑ∂ÂèëÁîüÁöÑÂèòÂºÇ</u>ÁöÑÈ≤ÅÊ£íÊÄßÔºå‰ªçÊúâËÆ∏Â§öÊú™Ëß£ÂÜ≥ÁöÑÁ†îÁ©∂ÈóÆÈ¢ò„ÄÇËøôÁ±ªÈóÆÈ¢òÂØπ‰∫éSSLÊñπÊ≥ïÁöÑ‰æùËµñÁ®ãÂ∫¶‰πüÂæàÂÖ≥ÈîÆ„ÄÇ</p> <p>Ê≠§Â§ñÔºåSSL ÊòØÁî±<u>ÁªèÈ™åÈ©±Âä®</u>ÁöÑÔºåÂÆÉÊúâËÆ∏Â§öÊ¥ªÂä®ÈÉ®‰ª∂Ôºà‰∏ªË¶ÅÊòØ<u>Ë∂ÖÂèÇÊï∞</u>ÔºâÔºåËøô‰∫õÈÉ®‰ª∂ÂèØËÉΩ‰ºöÂΩ±ÂìçÊúÄÁªàË°®ÂæÅÁöÑÂÖ≥ÈîÆÂ±ûÊÄßÔºåËÄå‰∏îÂú®Â∑≤ÂèëË°®ÁöÑ‰ΩúÂìÅ‰∏≠<u>‰∏ç‰∏ÄÂÆöÊúâËØ¶ÁªÜËØ¥Êòé</u>„ÄÇÂç≥Ôºå‰∏∫‰∫ÜÂºÄÂßãÁ†îÁ©∂SSLÊñπÊ≥ïÔºåÊàë‰ª¨ÂøÖÈ°ª<u>È¶ñÂÖàÂØπËøô‰∫õÊñπÊ≥ïËøõË°åËØ¶Â∞ΩÁöÑÂÆûËØÅÁ†îÁ©∂</u>ÔºåÊâçËÉΩÂÖÖÂàÜÊéåÊè°<u>ÊâÄÊúâËøô‰∫õÊ¥ªÂä®ÈÉ®‰ª∂ÁöÑÂΩ±ÂìçÂíåË°å‰∏∫</u>„ÄÇËøôÁßçÁªèÈ™åÁõ≤ÁÇπÈúÄË¶ÅÂ§ßÈáèÁöÑËÆ°ÁÆóËµÑÊ∫êÂíåÂ∑≤ÊúâÁöÑÂÆûË∑µÁªèÈ™åÔºåÂõ†Ê≠§ÂÖ∑ÊúâÂæàÂº∫ÁöÑÂ±ÄÈôêÊÄß„ÄÇÊÄª‰πãÔºåSOTA ÁöÑÊÄßËÉΩÊù•Ëá™Áúã‰ºº‰∏çÂêå‰ΩÜÂèàÁõ∏‰∫íÈáçÂè†ÁöÑÊñπÊ≥ïÔºåÁé∞ÊúâÁöÑÁêÜËÆ∫Á†îÁ©∂ÂæàÂ∞ëÔºåËÄåÂÆûÈôÖÂ∫îÁî®Âç¥ÂæàÂπøÊ≥õÔºåÂõ†Ê≠§ÈúÄË¶Å‰∏ÄÊú¨Áªü‰∏ÄÊäÄÊúØÂèäÂÖ∂‚ÄúÈÖçÊñπ‚ÄùÁöÑÊåáÂçóÔºåËøôÂØπÈôç‰Ωé SSL ÁöÑÁ†îÁ©∂Èó®ÊßõËá≥ÂÖ≥ÈáçË¶Å„ÄÇ</p> <p>Êàë‰ª¨ÁöÑÁõÆÊ†áÊòØ‰∏∫‰∫ÜÈôç‰Ωé‰ªé‰∫ãSSLÁ†îÁ©∂ÁöÑÈó®ÊßõÔºåÈÄöËøáÈì∫ËÆæÂü∫Á°ÄÂíå‰∏Ä‰∫õÁõ∏ÂØπËæÉÊñ∞ÁöÑSSLÊñπÊ≥ïÔºå‰ª•‰∏ÄÁßçcookbookÁöÑÈ£éÊ†ºÊù•ÂëàÁé∞„ÄÇ‰∏∫‰∫Ü‚ÄúÁÉπÈ•™‚ÄùÊàêÂäüÔºå‰Ω†ÂøÖÈ°ªÈ¶ñÂÖàÂ≠¶‰π†Âü∫Êú¨ÊäÄÊúØÔºöÂàáËèúÔºåÁÇíËèúÁ≠â„ÄÇÂú®Á¨¨ 2 ËäÇ‰∏≠ÔºåÊàë‰ª¨È¶ñÂÖà<u>‰ΩøÁî®ÈÄöÁî®ËØçÊ±á‰ªãÁªçËá™ÁõëÁù£Â≠¶‰π†ÁöÑÂü∫Êú¨ÊäÄÊúØ</u>„ÄÇÁâπÂà´ÊòØÔºåÊàë‰ª¨Â∞Ü‰ªéÁªü‰∏ÄÁöÑËßÜËßíÊù•<u>ÊèèËø∞Ëøô‰∫õÊñπÊ≥ïÁ≥ªÂàó‰ª•ÂèäÂ∞ÜÂÆÉ‰ª¨ÁöÑÁõÆÊ†áËÅîÁ≥ªËµ∑Êù•ÁöÑÁêÜËÆ∫‰∏ªÁ∫ø</u>„ÄÇÊàë‰ª¨Âú®Ê¶ÇÂøµÊ°Ü‰∏≠Á™ÅÂá∫‰∫ÜÊçüÂ§±È°πÊàñËÆ≠ÁªÉÁõÆÊ†áÁ≠âÂÖ≥ÈîÆÊ¶ÇÂøµ„ÄÇÁÑ∂ÂêéÔºå‰∏Ä‰∏™Âé®Â∏àÂøÖÈ°ªÂ≠¶‰ºöËøêÁî®ÊäÄÊúØÂéªÂÅöÊàê‰∏ÄÈÅìÁæéÂë≥ÁöÑËèúÔºåËøô‰πüÂ∞±ÈúÄË¶ÅÂ≠¶‰π†Áé∞ÊúâÁöÑËèúË∞±ÔºåÁªÑÂêàÈ£üÊùêÔºåËøòÊúâÂìÅÂë≥ËèúÂìÅ„ÄÇÂú®Á¨¨‰∏âËäÇ‰∏≠ÔºåÊàë‰ª¨<u>‰ªãÁªç‰∫ÜÂÆûÈôÖÊàêÂäüÂÆûÁé∞SSLÊñπÊ≥ï‰∏≠ÔºåÈúÄË¶ÅËÄÉËôëÁöÑÁÇπ„ÄÇÊàë‰ª¨ËÆ®ËÆ∫‰∫ÜÈÄöÂ∏∏ÁöÑËÆ≠ÁªÉËèúË∞±ÔºåÂåÖÊã¨Ë∂ÖÂèÇÊï∞ÁöÑÈÄâÊã©ÔºåÂ¶Ç‰ΩïÁªÑÂêà‰∏çÂêåÁªÑ‰ª∂ÔºàÊØîÂ¶ÇÁªìÊûÑÂíå‰ºòÂåñÂô®ÔºâÔºåËøòÊúâÂ¶Ç‰ΩïËØÑ‰ª∑SSLÊñπÊ≥ï„ÄÇÊàë‰ª¨ËøòÂ∞ÜÂàÜ‰∫´È°∂Â∞ñÁ†îÁ©∂‰∫∫ÂëòÂ∞±Â∏∏ËßÅÂüπËÆ≠ÈÖçÁΩÆÂíåÈô∑Èò±ÊèêÂá∫ÁöÑÂÆûÁî®Âª∫ËÆÆ</u>„ÄÇÊàë‰ª¨Â∏åÊúõËøôÊú¨ÊâãÂÜåËÉΩÊàê‰∏∫ÊàêÂäüËÆ≠ÁªÉÂíåÊé¢Á¥¢Ëá™ÁõëÁù£Â≠¶‰π†ÁöÑÂÆûÁî®Âü∫Á°Ä„ÄÇ</p> <h4 id="the-families-and-origins-of-ssl">The families and origins of SSL</h4> <p>Áî±‰∫é<u>Â§ßËßÑÊ®°ÁöÑÁâπÂà´Â§ßÁöÑÊï∞ÊçÆÈõÜÂíåÈ´òÂÜÖÂ≠òÁöÑGPUÁöÑÂèØËé∑ÂæóÊÄß</u>ÔºåËá™2020Âπ¥‰ª•Êù•ÔºåSSLÊñπÊ≥ïÂ∞±ÂºÄÂßãÂ§çÂÖ¥‰∫Ü„ÄÇ‰ΩÜÊòØSSLÁöÑËµ∑Ê∫êÂèØ‰ª•<u>ËøΩÊ∫ØÂà∞Ê∑±Â∫¶Â≠¶‰π†Âπ¥‰ª£ÁöÑÊúÄÂºÄÂßã</u>„ÄÇ</p> <h5 id="origins-of-ssl">Origins of SSL</h5> <p>ÂΩì‰ªäÁöÑÊñπÊ≥ïÈÉΩÂª∫Á´ã‰∫éÊàë‰ª¨‰ªé<u>Êó©ÊúüÂÆûÈ™å</u>‰∏≠Ëé∑ÂæóÂà∞ÁöÑÁü•ËØÜ„ÄÇÂú®Ëøô‰∏ÄÁ´†ËäÇ‰∏≠ÔºåÊàë‰ª¨Áªô‰∫Ü‰∏Ä‰∏™Âú®2020Âπ¥‰ª•ÂâçÂÖ≥‰∫éSSLÁÇπÂ≠êÁöÑÁÆÄËø∞„ÄÇËôΩÁÑ∂ËÆ∏Â§öÂÖ∑‰ΩìÊñπÊ≥ïÂ∑≤Áªè‰∏çÂÜçË¢´‰∏ªÊµÅ‰ΩøÁî®ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨‰∏çÂÜçËÉΩÂú®Âü∫ÂáÜÈóÆÈ¢ò‰∏äÊèê‰æõÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÊàë‰ª¨‰πü‰∏ç‰ºöÂØπÂÆÉ‰ª¨ËøõË°åËØ¶ÁªÜËÆ®ËÆ∫Ôºå‰ΩÜËøô‰∫õËÆ∫Êñá‰∏≠ÁöÑËßÇÁÇπÊûÑÊàê‰∫ÜËÆ∏Â§öÁé∞‰ª£ÊñπÊ≥ïÁöÑÂü∫Á°Ä„ÄÇÊØîÂ¶ÇÔºårestoring missing or distorted parts of an input or contrasting two views of the same imageÁöÑÊ†∏ÂøÉÁõÆÊ†áÂΩ¢Êàê‰∫ÜÁé∞‰ª£SSLÊñπÊ≥ïÁöÑÂü∫Á°Ä„ÄÇSSL <u>Êó©ÊúüÁöÑËøõÂ±ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®‰ª•‰∏ãÂá†Á±ª</u>ÔºàÊúâÊó∂Áõ∏‰∫íÈáçÂè†ÔºâÊñπÊ≥ïÁöÑÂºÄÂèë‰∏äÔºö</p> <ol> <li> <p><strong>Information restoration</strong>: Â§ßÈáèÁöÑÊñπÊ≥ïË¢´ÂºÄÂèëÊù•<u>ÈÅÆ‰ΩèÊàñËÄÖÁßªÈô§‰∏Ä‰∏™ÂõæÁâá‰∏≠ÁöÑ‰∏Ä‰∫õ‰∏úË•ø</u>ÔºåÁÑ∂Âêé<u>ËÆ≠ÁªÉ‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊù•ÊÅ¢Â§çÁº∫Â§±ÈÉ®ÂàÜÁöÑ‰ø°ÊÅØ</u>„ÄÇÂü∫‰∫é‰∏äËâ≤ÁöÑSSLÊñπÊ≥ïÔºà<u>Colorization-based</u>ÔºâSSL methodsÊää‰∏Ä‰∏™ÂõæÁâá<u>ËΩ¨Êç¢ÊàêÁÅ∞Â∫¶Âõæ</u>ÔºåÁÑ∂ÂêéËÆ≠ÁªÉ‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊù•<u>È¢ÑÊµãÂéüÊú¨ÁöÑRGBÂÄº</u>„ÄÇÁî±‰∫éÁùÄËâ≤ÈúÄË¶Å‰∫ÜËß£ÂØπË±°ÁöÑËØ≠‰πâÂíåËæπÁïåÔºåÂõ†Ê≠§<u>ÁùÄËâ≤Ë¢´ËØÅÊòéÊòØÊó©ÊúüÁöÑÂØπË±°ÂàÜÂâ≤ SSL ÊñπÊ≥ï</u>„ÄÇËøôÁßç‰ø°ÊÅØÊÅ¢Â§çÊúÄÁõ¥ËßÇÁÆÄÂçïÁöÑÂ∫îÁî®ÊòØÈÅÆ‰ΩèÂç≥<u>Êå™ÂéªÂõæÂÉèÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÁÑ∂ÂêéËÆ≠ÁªÉ‰∏Ä‰∏™Á•ûÁªèÁΩëÁªúÊù•ÁªôÁº∫Â§±ÁöÑÂÉèÁ¥†ÁùÄËâ≤</u>„ÄÇËøô‰∏™ÁÇπÂ≠êËøõÂåñÊàê‰∫ÜMasked auto-encoding methodsÔºåÂÖ∂‰∏≠Ôºå<u>Êé©ËîΩÂå∫ÂüüÊòØÂõæÂÉèpatchesÁöÑÁªìÂêà‰ΩìÔºàunionÔºâÔºåÂèØ‰ª•‰ΩøÁî®transfomerËøõË°åÈ¢ÑÊµã</u>„ÄÇ</p> </li> <li> <p><strong>Using temporal relationships in video</strong>: Â∞ΩÁÆ°Ëøô‰∏™ÂõûÈ°æÁöÑÁÑ¶ÁÇπÊòØÂú®ÂõæÂÉèÔºàËÄåÈùûËßÜÈ¢ëÔºâÂ§ÑÁêÜ‰∏äÔºå‰∏ÄÁ≥ªÂàó‰∏ìÈó®ÊñπÊ≥ïÂ∑≤ÁªèË¢´ÂºÄÂèëÂá∫Êù•ÔºåÈÄöËøáÂØπ<u>ËßÜÈ¢ëËøõË°åÈ¢ÑËÆ≠ÁªÉÊù•Â≠¶‰π†ÂçïÂõæÂÉèË°®ÂæÅÔºàsingle-image representationsÔºâ</u>„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºå<u>‰ø°ÊÅØËøòÂéüÔºàinformation restorationÔºâÊñπÊ≥ïÂØπËßÜÈ¢ëÁâπÂà´ÊúâÁî®</u>ÔºåÂõ†‰∏∫ËßÜÈ¢ëÂåÖÂê´Â§öÁßçÂèØËÉΩË¢´Â±èËîΩÁöÑ‰ø°ÊÅØÊ®°Âºè„ÄÇWang and Gupta ‰ΩøÁî®<u>‰∏âÈáçÊçüÂ§±Ôºàtriplet lossÔºâÂØπÊ®°ÂûãËøõË°åÈ¢ÑËÆ≠ÁªÉ</u>Ôºå‰ª•<u>ÊèêÈ´ò‰∏§‰∏™‰∏çÂêåÂ∏ß‰∏≠Âêå‰∏Ä‰∏™Áâ©‰ΩìË°®ÂæÅÁöÑÁõ∏‰ººÊÄß</u>„ÄÇÊúÄÁªàÁöÑÁªìÊûúÊ®°ÂûãÂú®Áâ©‰ΩìÊ£ÄÊµã‰∏äË°®Áé∞‰∏çÈîô„ÄÇPathak et al. ËÆ≠ÁªÉ‰∫Ü‰∏Ä‰∏™Ê®°ÂûãÊù•<u>È¢ÑÊµãÁâ©‰ΩìÂú®Âçï‰∏ÄÂ∏ß‰∏≠ÁöÑËøêÂä®</u>ÔºåË∞ÉÊï¥Áî±Ê≠§‰∫ßÁîüÁöÑfeaturesÊù•Ëß£ÂÜ≥Âçï‰∏ÄÂ∏ßÔºàsingle-frameÔºâÊ£ÄÊµãÈóÆÈ¢ò„ÄÇAgrawal et al. <u>È¢ÑÊµãÂ§öÂ∏ßÂõæÂÉè‰∏≠ÊëÑÂÉèÊú∫ÁöÑËá™ÊàëËøêÂä®</u>Ôºàego-motionÔºâËΩ®Ëøπ„ÄÇOwens et al. ÊèêÂá∫<u>‰ªéËßÜÈ¢ë‰∏≠ÂéªÊéâÈü≥ËΩ®ÔºåÁÑ∂ÂêéÈ¢ÑÊµãÁº∫Â§±ÁöÑÂ£∞Èü≥</u>„ÄÇÂØπ‰∫éÊ∑±Â∫¶Êò†Â∞ÑÔºàdepth mappingÔºâÁ≠â‰∏ì‰∏öÂ∫îÁî®ÔºåÊúâ‰∫∫ÊèêÂá∫‰∫ÜËá™ÁõëÁù£ÊñπÊ≥ïÔºå‰ªé<u>Êú™Ê†áÊòéÁöÑÂõæÂÉèÂØπ‰∏≠Â≠¶‰π†ÂçïÁõÆÊ∑±Â∫¶</u>Ôºàmonocular depthÔºâÊ®°ÂûãÔºåÁÑ∂Âêé<u>‰ªéÂçïÊëÑÂÉèÂ§¥ËßÜÈ¢ëÔºàsingle-camera videoÔºâ‰∏≠Â≠¶‰π†Â∏ß</u>„ÄÇÊ≠§Á±ªÊñπÊ≥ï‰ªçÊòØ‰∏Ä‰∏™Ê¥ªË∑ÉÁöÑÁ†îÁ©∂È¢ÜÂüü„ÄÇ</p> </li> <li> <p><strong>Learning spatial context</strong>: Ëøô‰∏™ÁßçÁ±ªÁöÑÊñπÊ≥ïÊòØ<u>ËÆ≠ÁªÉ‰∏Ä‰∏™Ê®°ÂûãÊù•ÁêÜËß£Áâ©‰ΩìÂú®‰∏Ä‰∏™Âú∫ÊôØÁöÑÁõ∏ÂØπ‰ΩçÁΩÆÂíåÊñπÂêë</u>„ÄÇRotNet ÈÄöËøáÈöèÊú∫ÊóãËΩ¨Êù•<u>Êé©ÁõñÈáçÂäõÊñπÂêëÔºåÁÑ∂ÂêéË¶ÅÊ±ÇÊ®°ÂûãÈ¢ÑÊµãÊóãËΩ¨</u>„ÄÇDoersch et al. ÊòØÊúÄÊó©ÁöÑ SSL ÊñπÊ≥ï‰πã‰∏ÄÔºåÂÆÉÂèØ‰ª•<u>ÁÆÄÂçïÂú∞È¢ÑÊµãÂõæÂÉè‰∏≠‰∏§‰∏™ÈöèÊú∫ÈááÊ†∑ÁöÑpatchÁöÑÁõ∏ÂØπ‰ΩçÁΩÆ</u>„ÄÇËøô‰∏™ÊñπÊ≥ïÂêéÊù•<u>Ë¢´JigsawÊñπÊ≥ïÂèñ‰ª£</u>‰∫Ü„ÄÇJigsawÊñπÊ≥ïÂ∞±ÊòØÊää<u>‰∏Ä‰∏™ÂõæÁâáÂàÜÊàê‰∏ÄÂàódisjointÁöÑpatchesÁÑ∂ÂêéÈ¢ÑÊµãÁõ∏‰∫íÁöÑÁõ∏ÂØπ‰ΩçÁΩÆ</u>„ÄÇ‰∏Ä‰∏™‰∏çÂêåÁöÑÁ©∫Èó¥‰ªªÂä°ÊòØÂ≠¶‰π†Êï∞Êï∞ÔºöÊ®°ÂûãÊòØÂú®Ëá™ÁõëÁù£ÊñπÂºèË¢´ËÆ≠ÁªÉÊù•<u>ËæìÂá∫‰∏Ä‰∏™ÂõæÂÉè‰∏≠Áâ©‰ΩìÁöÑÊï∞Èáè</u>„ÄÇ</p> </li> <li> <p><strong>Grouping similar images together</strong>: ÈÄöËøáÂ∞Ü<u>ËØ≠‰πâÁõ∏‰ººÁöÑÂõæÂÉèÂàÜÁªÑ</u>ÔºåÂèØ‰ª•Â≠¶‰π†Âà∞<u>‰∏∞ÂØåÁöÑÁâπÂæÅ</u>„ÄÇK-meansËÅöÁ±ªÂ∞±ÊòØÂú®‰º†ÁªüÁöÑÊú∫Âô®Â≠¶‰π†‰∏≠ÊúÄÂπøÊ≥õËøêÁî®ÁöÑÊñπÊ≥ï‰πã‰∏Ä„ÄÇËÆ∏Â§öÁ†îÁ©∂ÈÉΩÂØπ k-means ËøõË°å‰∫ÜË∞ÉÊï¥Ôºå‰ª•‰æøÂà©Áî®Á•ûÁªèÊ®°ÂûãÂÅö SSL„ÄÇ<u>Ê∑±Â∫¶ËÅöÁ±ªÊäÄÊúØÈÄöËøáÂú®ÁâπÂæÅÁ©∫Èó¥Ôºàfeature spaceÔºâ‰∏≠ÊâßË°å k-means Êù•‰∫§Êõø‰∏∫ÂõæÂÉèÂàÜÈÖçÊ†áÁ≠æ</u>ÔºåÂπ∂<u>Êõ¥Êñ∞Ê®°Âûã‰ª•respectËøô‰∫õÂàÜÈÖçÁöÑÁ±ªÂà´Ê†áÁ≠æ</u>„ÄÇËøô‰∏™ÊñπÊ≥ïÊúÄËøëÁöÑÂ§ÑÁêÜÊñπÂºèÊòØ‰ΩøÁî®<u>mean-shiftÊõ¥Êñ∞Êù•ÊääfeaturesÊé®Âà∞‰ªñ‰ª¨ÁöÑËÅöÁ±ª‰∏≠ÂøÉ</u>ÔºåËÄå‰∏îÂ∑≤ÁªèË¢´ËØÅÊòéÂèØ‰ª•Áî®Êù•<u>Ë°•ÂÖÖBYOL</u>ÊñπÊ≥ï„ÄÇBYOLÊòØ‰∏ÄÁßçÂü∫‰∫é‰∏§‰∏™ÁΩëÁªúÁöÑÊñπÊ≥ïÔºåÂÖ∂ÁõÆÊ†áÊòØÈ¢ÑÊµã<u>ÊØè‰∏™Ê†∑Êú¨ÁöÑ‰º™Ê†áÁ≠æ</u>„ÄÇÂØπÊ∑±Â∫¶ËÅöÁ±ªÁöÑÂà´ÁöÑÊèêÂçáÂåÖÊã¨Âú®ÁâπÂæÅÁ©∫Èó¥Áî®optimal transport methodsÊù•ÂàõÂª∫Êõ¥Êúâ‰ø°ÊÅØÁöÑËÅöÁ±ª„ÄÇ</p> </li> <li> <p><strong>Generative models</strong>: ‰∏ÄÁßçÊó©ÊúüÁöÑÊúâÂΩ±ÂìçÂäõÁöÑSSLÊñπÊ≥ïÊòØË¥™Â©™Â±ÇÁ∫ßÔºàgreedy layer-wiseÔºâÈ¢ÑËÆ≠ÁªÉÔºåÂÖ∂‰∏≠ÔºåÊ∑±Â∫¶ÁΩëÁªúÁöÑÂêÑÂ±Ç‰ΩøÁî®autoencoder lossËøõË°åÈÄêÂ±ÇËÆ≠ÁªÉ„ÄÇÂΩìÊó∂ÁöÑ‰∏ÄÁßçÁ±ª‰ººÊñπÊ≥ïÊòØ‰ΩøÁî®ÂèóÈôêÁéªÂ∞îÂÖπÊõºÊú∫ (RBMs)ÔºåËøôÁßçÊú∫Âô®ÂèØ‰ª•ËøõË°åÂàÜÂ±ÇËÆ≠ÁªÉÂíåÂ†ÜÂè†Ôºå‰ª•ÂàõÂª∫Ê∑±Â∫¶‰ø°ÂøµÁΩë„ÄÇËôΩÁÑ∂Ëøô‰∫õÊñπÊ≥ïÂ∑≤Ë¢´ÊîæÂºÉÔºåËΩ¨ËÄåÈááÁî®Êõ¥ÁÆÄÂçïÁöÑÂàùÂßãÂåñÁ≠ñÁï•ÂíåÊõ¥ÈïøÁöÑËÆ≠ÁªÉÊó∂Èó¥Ôºå‰ΩÜÂÆÉ‰ª¨Âú®ÂéÜÂè≤‰∏äÂØπ SSL ÁöÑ‰ΩøÁî®‰∫ßÁîü‰∫ÜÊ∑±ËøúÂΩ±ÂìçÔºåÂõ†‰∏∫ÂÆÉ‰ª¨‰øÉÊàê‰∫ÜÁ¨¨‰∏ÄÊâπ ‚ÄúÊ∑±Â∫¶ ‚ÄúÁΩëÁªúÁöÑËÆ≠ÁªÉ„ÄÇÂêéÊù•Âú®auto-encodersÁöÑË°®ÂæÅÂ≠¶‰π†ÁöÑËÉΩÂäõ‰∏äÁöÑÊèêÂçáÊúâÂåÖÊã¨denoising autoencodersÔºåcross-channel predictionÔºåÂíådeep canoncically correlated autoencoders„ÄÇ‰ΩÜÊòØÊúÄÁªàÂèëÁé∞ÔºåÂΩìË¶ÅÊ±Çauto-encoderÊÅ¢Â§çÂÖ∂ËæìÂÖ•ÁöÑÁº∫Â§±ÈÉ®ÂàÜÊó∂ÔºåË°®ÂæÅËΩ¨ÁßªÊÄß‰ºöÊõ¥Â•ΩÔºåËøôÂ∞±ÂΩ¢Êàê‰∫Ü SSL ÊñπÊ≥ï‰∏≠ÁöÑ ‚Äú‰ø°ÊÅØÊÅ¢Â§ç ‚ÄúÁ±ªÂà´„ÄÇ</p> <p>ÁîüÊàêÂºèÂØπÊäóÁΩëÁªúÁî±‰∏Ä‰∏™ÂõæÂÉèÁîüÊàêÂô®Âíå‰∏Ä‰∏™Âà§Âà´Âô®ÁªÑÊàêÔºåÂà§Âà´Âô®Âå∫ÂàÜÁúüÂõæÂÉèÂíåÁîüÊàêÁöÑÂÅáÂõæÂÉè„ÄÇËøôÂØπÊ®°ÂûãÁöÑ‰∏§‰∏™ÁªÑÊàêÈÉ®ÂàÜÈÉΩÂèØ‰ª•Âú®Ê≤°ÊúâÁõëÁù£ÁöÑÊÉÖÂÜµ‰∏ãËøõË°åËÆ≠ÁªÉÔºåËÄå‰∏î‰∏§ËÄÖÈÉΩÂèØËÉΩÂåÖÂê´ÂØπËøÅÁßªÂ≠¶‰π†ÊúâÁî®ÁöÑÁü•ËØÜ„ÄÇÊó©ÊúüÁöÑGANsÁöÑËÆ∫Êñá‰ΩøÁî® GAN ÁªÑ‰ª∂ËøõË°å‰∏ãÊ∏∏ÂõæÂÉèÂàÜÁ±ªÂÆûÈ™å„ÄÇÊ≠§Â§ñÔºåËøòÂºÄÂèë‰∫Ü‰∏ìÈó®ÁöÑÁâπÂæÅÂ≠¶‰π†Á®ãÂ∫èÊù•‰øÆÊîπÂà§Âà´Âô®„ÄÅÊ∑ªÂä†ÁîüÊàêÂô®ÊàñÂ≠¶‰π†‰ªéÂõæÂÉèÂà∞ÊΩúÁ©∫Èó¥ÁöÑÈ¢ùÂ§ñÊò†Â∞ÑÔºå‰ª•ÊîπËøõËøÅÁßªÂ≠¶‰π†„ÄÇ</p> </li> <li> <p><strong>Multi-view invariance</strong>: ËÆ∏Â§öÁé∞‰ª£ SSL ÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÊàë‰ª¨Âú®Êú¨Êñá‰∏≠ÈáçÁÇπËÆ®ËÆ∫ÁöÑÊñπÊ≥ïÔºåÈÉΩ‰ΩøÁî®ÂØπÊØîÂ≠¶‰π†Ôºàcontrastive learningÔºâÊù•ÂàõÂª∫<u>‰∏çÂèóÁÆÄÂçïÂèòÊç¢ÂΩ±ÂìçÁöÑÁâπÂæÅË°®ÂæÅ</u>„ÄÇÂØπÊØîÂ≠¶‰π†ÁöÑÁêÜÂøµÊòØÈºìÂä±Ê®°Âûã<u>‰ª•Áõ∏‰ººÁöÑÊñπÂºèË°®Á§∫ËæìÂÖ•ÁöÑ‰∏§‰∏™Â¢ûÂº∫ÁâàÊú¨</u>„ÄÇÂú®ÂØπÊØîÂ≠¶‰π†Ë¢´ÂπøÊ≥õÈááÁî®‰πãÂâçÔºåÊúâËÆ∏Â§öÊñπÊ≥ï‰ª•ÂêÑÁßçÊñπÂºèÂº∫Âà∂‰øùÊåÅ‰∏çÂèòÊÄßÔºå‰ªéËÄåÂºïÈ¢Ü‰∫ÜËøô‰∏ÄÊñπÂêë„ÄÇ</p> <p>‰ªéÊó†Ê†áÁ≠æÊï∞ÊçÆ‰∏≠Â≠¶‰π†ÁöÑÊúÄÊµÅË°åÊ°ÜÊû∂‰πã‰∏ÄÔºåÊòØ‰ΩøÁî®<u>Âº±ËÆ≠ÁªÉÁΩëÁªú‰∏∫ÂõæÂÉèÊ∑ªÂä†‰º™Ê†áÁ≠æ</u>ÔºàpseudolabelsÔºâÔºåÁÑ∂Âêé‰ª•Ê†áÂáÜ<u>ÁõëÁù£ÊñπÂºè‰ΩøÁî®Ëøô‰∫õÊ†áÁ≠æËøõË°åËÆ≠ÁªÉ</u>„ÄÇËøôÁßçÊñπÊ≥ïÂêéÊù•ÂæóÂà∞‰∫ÜÊîπËøõÔºå<u>Âä†Âº∫‰∫ÜÂØπÂèòÊç¢ÁöÑ‰∏çÂèòÊÄß</u>Ôºàinvariance to transformationsÔºâ„ÄÇËôöÊãüÂØπÊäóËÆ≠ÁªÉÔºàvirtual adversarial trainingÔºâ<u>Âà©Áî®ÂõæÂÉèÁöÑ‰º™Ê†áÁ≠æÂØπÁΩëÁªúËøõË°åËÆ≠ÁªÉ</u>ÔºåÊ≠§Â§ñËøòËøõË°å<u>ÂØπÊäóËÆ≠ÁªÉ</u>Ôºå‰ΩøÂ≠¶‰π†Âà∞ÁöÑÁâπÂæÅÂá†‰πé‰∏çÂèóËæìÂÖ•ÂõæÂÉèÂæÆÂ∞èÊâ∞Âä®Ôºàsmall perturbationsÔºâÁöÑÂΩ±Âìç„ÄÇÂêéÊù•ÁöÑÂ∑•‰ΩúÈáçÁÇπÊòØ<u>‰øùÊåÅÊï∞ÊçÆÂ¢ûÂº∫ÔºàaugmentationÔºâÂèòÊç¢ÁöÑ‰∏çÂèòÊÄß</u>Ôºàmaintain invariance to data augmentation transformsÔºâ„ÄÇËøôÁ±ªÊó©ÊúüÁöÑÈáçË¶ÅÊñπÊ≥ïÂåÖÊã¨ MixMatchÔºåËØ•ÊñπÊ≥ïÈÄöËøá<u>Âπ≥Âùá</u>ÔºàaverageÔºâÁΩëÁªúÂú®<u>Â§ö‰∏™‰∏çÂêåÈöèÊú∫Â¢ûÂº∫</u>ÔºàaugmentationÔºâ<u>ËÆ≠ÁªÉÂõæÂÉè‰∏äÁöÑËæìÂá∫</u>Êù•ÈÄâÊã©<u>‰º™Ê†áÁ≠æ</u>Ôºå‰ªéËÄåÂæóÂà∞<u>Â¢ûÂº∫‰∏çÂèòÁöÑÊ†áÁ≠æ</u>„ÄÇÂ§ßÁ∫¶Âú®Âêå‰∏ÄÊó∂Èó¥Ôºå‰∫∫‰ª¨ÂèëÁé∞ÔºåÈÄöËøá<u>ËÆ≠ÁªÉÁΩëÁªú‰Ωø‰∏çÂêåËßÜËßí‰∏ãÁöÑÂõæÂÉèË°®ÂæÅ‰πãÈó¥ÁöÑ‰∫í‰ø°ÊÅØÊúÄÂ§ßÂåñ</u>ÔºåÂèØ‰ª•ÂÆûÁé∞<u>ËâØÂ•ΩÁöÑ SSL ÊÄßËÉΩ</u>„ÄÇËøô‰∫õ‰ª•Â¢ûÂº∫‰∏∫Âü∫Á°ÄÔºàaugmentation-basedÔºâÁöÑÊñπÊ≥ïÂú®‰∏äËø∞ÊóßÊñπÊ≥ïÂíåÊú¨ÊñáÈáçÁÇπËÆ®ËÆ∫ÁöÑÁé∞‰ª£ÊñπÊ≥ï‰πãÈó¥Êû∂Ëµ∑‰∫Ü‰∏ÄÂ∫ßÊ°•Ê¢Å„ÄÇ</p> </li> </ol> <p>Êúâ‰∫ÜËøô‰∫õÊ∏äÊ∫êÔºåÊàë‰ª¨Áé∞Âú®Â∞Ü SSL ÂàÜÊàêÂõõÂ§ßÁ≥ªÂàóÔºöÊ∑±Â∫¶Â∫¶ÈáèÂ≠¶‰π†ÔºàDeep Metric LearningÔºâÁ≥ªÂàó„ÄÅËá™È¶èÂàÜÔºàSelf-DistillationÔºâÁ≥ªÂàó„ÄÅÂÖ∏ÂûãÁõ∏ÂÖ≥ÂàÜÊûêÔºàCanonical Correlation AnalysisÔºâÁ≥ªÂàóÂíåÂ±èËîΩÂõæÂÉèÂª∫Ê®°ÔºàMasked Image ModelingÔºâÁ≥ªÂàó„ÄÇ</p> <p>Âú®Êé•‰∏ãÊù•ÁöÑÊñáÁ´†‰∏≠ÔºåÂ∞Ü‰ºö‰ª•ÂéüËëóÁöÑÊñπÂºèÂëàÁé∞ÊëòÂΩïÊù•ÂΩ¢ÊàêÁ¨îËÆ∞„ÄÇ</p>]]></content><author><name></name></author><category term="study"/><category term="ucph"/><category term="ssl"/><summary type="html"><![CDATA[This is the first part of this book.]]></summary></entry><entry><title type="html">a post with code diff</title><link href="https://liuying-1.github.io/blog/2024/code-diff/" rel="alternate" type="text/html" title="a post with code diff"/><published>2024-01-27T19:22:00+00:00</published><updated>2024-01-27T19:22:00+00:00</updated><id>https://liuying-1.github.io/blog/2024/code-diff</id><content type="html" xml:base="https://liuying-1.github.io/blog/2024/code-diff/"><![CDATA[<p>You can display diff code by using the regular markdown syntax:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff
</span><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")
</span></code></pre></div></div> <p>But this is difficult to read, specially if you have a large diff. You can use <a href="https://diff2html.xyz/">diff2html</a> to display a more readable version of the diff. For this, just use <code class="language-plaintext highlighter-rouge">diff2html</code> instead of <code class="language-plaintext highlighter-rouge">diff</code> for the code block language:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff2html
</span><span class="sb">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
--- a/sample.js
+++ b/sample.js
@@ -1 +1 @@
-console.log("Hello World!")
+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>If we use a longer example, for example <a href="https://github.com/rtfpessoa/diff2html/commit/c2c253d3e3f8b8b267f551e659f72b44ca2ac927">this commit from diff2html</a>, it will generate the following output:</p> <pre><code class="language-diff2html">From 2aaae31cc2a37bfff83430c2c914b140bee59b6a Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sun, 9 Oct 2016 16:41:54 +0100
Subject: [PATCH 1/2] Initial template override support

---
 scripts/hulk.js                    |  4 ++--
 src/diff2html.js                   |  3 +--
 src/file-list-printer.js           | 11 ++++++++---
 src/hoganjs-utils.js               | 29 +++++++++++++++++------------
 src/html-printer.js                |  6 ++++++
 src/line-by-line-printer.js        |  6 +++++-
 src/side-by-side-printer.js        |  6 +++++-
 test/file-list-printer-tests.js    |  2 +-
 test/hogan-cache-tests.js          | 18 +++++++++++++++---
 test/line-by-line-tests.js         |  3 +--
 test/side-by-side-printer-tests.js |  3 +--
 11 files changed, 62 insertions(+), 29 deletions(-)

diff --git a/scripts/hulk.js b/scripts/hulk.js
index 5a793c18..a4b1a4d5 100755
--- a/scripts/hulk.js
+++ b/scripts/hulk.js
@@ -173,11 +173,11 @@ function namespace(name) {
 // write a template foreach file that matches template extension
 templates = extractFiles(options.argv.remain)
   .map(function(file) {
-    var openedFile = fs.readFileSync(file, 'utf-8');
+    var openedFile = fs.readFileSync(file, 'utf-8').trim();
     var name;
     if (!openedFile) return;
     name = namespace(path.basename(file).replace(/\..*$/, ''));
-    openedFile = removeByteOrderMark(openedFile.trim());
+    openedFile = removeByteOrderMark(openedFile);
     openedFile = wrap(file, name, openedFile);
     if (!options.outputdir) return openedFile;
     fs.writeFileSync(path.join(options.outputdir, name + '.js')
diff --git a/src/diff2html.js b/src/diff2html.js
index 21b0119e..64e138f5 100644
--- a/src/diff2html.js
+++ b/src/diff2html.js
@@ -7,7 +7,6 @@

 (function() {
   var diffParser = require('./diff-parser.js').DiffParser;
-  var fileLister = require('./file-list-printer.js').FileListPrinter;
   var htmlPrinter = require('./html-printer.js').HtmlPrinter;

   function Diff2Html() {
@@ -43,7 +42,7 @@

     var fileList = '';
     if (configOrEmpty.showFiles === true) {
-      fileList = fileLister.generateFileList(diffJson, configOrEmpty);
+      fileList = htmlPrinter.generateFileListSummary(diffJson, configOrEmpty);
     }

     var diffOutput = '';
diff --git a/src/file-list-printer.js b/src/file-list-printer.js
index e408d9b2..1e0a2c61 100644
--- a/src/file-list-printer.js
+++ b/src/file-list-printer.js
@@ -8,11 +8,16 @@
 (function() {
   var printerUtils = require('./printer-utils.js').PrinterUtils;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var baseTemplatesPath = 'file-summary';
   var iconsBaseTemplatesPath = 'icon';

-  function FileListPrinter() {
+  function FileListPrinter(config) {
+    this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   FileListPrinter.prototype.generateFileList = function(diffFiles) {
@@ -38,5 +43,5 @@
     });
   };

-  module.exports.FileListPrinter = new FileListPrinter();
+  module.exports.FileListPrinter = FileListPrinter;
 })();
diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 9949e5fa..0dda08d7 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -8,18 +8,19 @@
 (function() {
   var fs = require('fs');
   var path = require('path');
-
   var hogan = require('hogan.js');

   var hoganTemplates = require('./templates/diff2html-templates.js');

-  var templatesPath = path.resolve(__dirname, 'templates');
+  var extraTemplates;

-  function HoganJsUtils() {
+  function HoganJsUtils(configuration) {
+    this.config = configuration || {};
+    extraTemplates = this.config.templates || {};
   }

-  HoganJsUtils.prototype.render = function(namespace, view, params, configuration) {
-    var template = this.template(namespace, view, configuration);
+  HoganJsUtils.prototype.render = function(namespace, view, params) {
+    var template = this.template(namespace, view);
     if (template) {
       return template.render(params);
     }
@@ -27,17 +28,16 @@
     return null;
   };

-  HoganJsUtils.prototype.template = function(namespace, view, configuration) {
-    var config = configuration || {};
+  HoganJsUtils.prototype.template = function(namespace, view) {
     var templateKey = this._templateKey(namespace, view);

-    return this._getTemplate(templateKey, config);
+    return this._getTemplate(templateKey);
   };

-  HoganJsUtils.prototype._getTemplate = function(templateKey, config) {
+  HoganJsUtils.prototype._getTemplate = function(templateKey) {
     var template;

-    if (!config.noCache) {
+    if (!this.config.noCache) {
       template = this._readFromCache(templateKey);
     }

@@ -53,6 +53,7 @@

     try {
       if (fs.readFileSync) {
+        var templatesPath = path.resolve(__dirname, 'templates');
         var templatePath = path.join(templatesPath, templateKey);
         var templateContent = fs.readFileSync(templatePath + '.mustache', 'utf8');
         template = hogan.compile(templateContent);
@@ -66,12 +67,16 @@
   };

   HoganJsUtils.prototype._readFromCache = function(templateKey) {
-    return hoganTemplates[templateKey];
+    return extraTemplates[templateKey] || hoganTemplates[templateKey];
   };

   HoganJsUtils.prototype._templateKey = function(namespace, view) {
     return namespace + '-' + view;
   };

-  module.exports.HoganJsUtils = new HoganJsUtils();
+  HoganJsUtils.prototype.compile = function(templateStr) {
+    return hogan.compile(templateStr);
+  };
+
+  module.exports.HoganJsUtils = HoganJsUtils;
 })();
diff --git a/src/html-printer.js b/src/html-printer.js
index 585d5b66..13f83047 100644
--- a/src/html-printer.js
+++ b/src/html-printer.js
@@ -8,6 +8,7 @@
 (function() {
   var LineByLinePrinter = require('./line-by-line-printer.js').LineByLinePrinter;
   var SideBySidePrinter = require('./side-by-side-printer.js').SideBySidePrinter;
+  var FileListPrinter = require('./file-list-printer.js').FileListPrinter;

   function HtmlPrinter() {
   }
@@ -22,5 +23,10 @@
     return sideBySidePrinter.generateSideBySideJsonHtml(diffFiles);
   };

+  HtmlPrinter.prototype.generateFileListSummary = function(diffJson, config) {
+    var fileListPrinter = new FileListPrinter(config);
+    return fileListPrinter.generateFileList(diffJson);
+  };
+
   module.exports.HtmlPrinter = new HtmlPrinter();
 })();
diff --git a/src/line-by-line-printer.js b/src/line-by-line-printer.js
index b07eb53c..d230bedd 100644
--- a/src/line-by-line-printer.js
+++ b/src/line-by-line-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'line-by-line';
   var iconsBaseTemplatesPath = 'icon';
@@ -19,6 +20,9 @@

   function LineByLinePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   LineByLinePrinter.prototype.makeFileDiffHtml = function(file, diffs) {
diff --git a/src/side-by-side-printer.js b/src/side-by-side-printer.js
index bbf1dc8d..5e3033b3 100644
--- a/src/side-by-side-printer.js
+++ b/src/side-by-side-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'side-by-side';
   var iconsBaseTemplatesPath = 'icon';
@@ -26,6 +27,9 @@

   function SideBySidePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   SideBySidePrinter.prototype.makeDiffHtml = function(file, diffs) {
diff --git a/test/file-list-printer-tests.js b/test/file-list-printer-tests.js
index a502a46f..60ea3208 100644
--- a/test/file-list-printer-tests.js
+++ b/test/file-list-printer-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var fileListPrinter = require('../src/file-list-printer.js').FileListPrinter;
+var fileListPrinter = new (require('../src/file-list-printer.js').FileListPrinter)();

 describe('FileListPrinter', function() {
   describe('generateFileList', function() {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 190bf6f8..3bb754ac 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var HoganJsUtils = require('../src/hoganjs-utils.js').HoganJsUtils;
+var HoganJsUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)();
 var diffParser = require('../src/diff-parser.js').DiffParser;

 describe('HoganJsUtils', function() {
@@ -21,16 +21,28 @@ describe('HoganJsUtils', function() {
       });
       assert.equal(emptyDiffHtml, result);
     });
+
     it('should render view without cache', function() {
       var result = HoganJsUtils.render('generic', 'empty-diff', {
         contentClass: 'd2h-code-line',
         diffParser: diffParser
       }, {noCache: true});
-      assert.equal(emptyDiffHtml + '\n', result);
+      assert.equal(emptyDiffHtml, result);
     });
+
     it('should return null if template is missing', function() {
-      var result = HoganJsUtils.render('generic', 'missing-template', {}, {noCache: true});
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)({noCache: true});
+      var result = hoganUtils.render('generic', 'missing-template', {});
       assert.equal(null, result);
     });
+
+    it('should allow templates to be overridden', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+
+      var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
diff --git a/test/line-by-line-tests.js b/test/line-by-line-tests.js
index 1cd92073..8869b3df 100644
--- a/test/line-by-line-tests.js
+++ b/test/line-by-line-tests.js
@@ -14,7 +14,7 @@ describe('LineByLinePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expected, fileHtml);
     });
@@ -422,7 +422,6 @@ describe('LineByLinePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                &lt;/tbody&gt;\n' +
         '            &lt;/table&gt;\n' +
         '        &lt;/div&gt;\n' +
diff --git a/test/side-by-side-printer-tests.js b/test/side-by-side-printer-tests.js
index 76625f8e..771daaa5 100644
--- a/test/side-by-side-printer-tests.js
+++ b/test/side-by-side-printer-tests.js
@@ -14,7 +14,7 @@ describe('SideBySidePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expectedRight, fileHtml.right);
       assert.equal(expectedLeft, fileHtml.left);
@@ -324,7 +324,6 @@ describe('SideBySidePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                    &lt;/tbody&gt;\n' +
         '                &lt;/table&gt;\n' +
         '            &lt;/div&gt;\n' +

From f3cadb96677d0eb82fc2752dc3ffbf35ca9b5bdb Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sat, 15 Oct 2016 13:21:22 +0100
Subject: [PATCH 2/2] Allow uncompiled templates

---
 README.md                 |  3 +++
 src/hoganjs-utils.js      |  7 +++++++
 test/hogan-cache-tests.js | 24 +++++++++++++++++++++++-
 3 files changed, 33 insertions(+), 1 deletion(-)

diff --git a/README.md b/README.md
index 132c8a28..46909f25 100644
--- a/README.md
+++ b/README.md
@@ -98,6 +98,9 @@ The HTML output accepts a Javascript object with configuration. Possible options
   - `synchronisedScroll`: scroll both panes in side-by-side mode: `true` or `false`, default is `false`
   - `matchWordsThreshold`: similarity threshold for word matching, default is 0.25
   - `matchingMaxComparisons`: perform at most this much comparisons for line matching a block of changes, default is `2500`
+  - `templates`: object with previously compiled templates to replace parts of the html
+  - `rawTemplates`: object with raw not compiled templates to replace parts of the html
+  &gt; For more information regarding the possible templates look into [src/templates](https://github.com/rtfpessoa/diff2html/tree/master/src/templates)

 ## Diff2HtmlUI Helper

diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 0dda08d7..b2e9c275 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -17,6 +17,13 @@
   function HoganJsUtils(configuration) {
     this.config = configuration || {};
     extraTemplates = this.config.templates || {};
+
+    var rawTemplates = this.config.rawTemplates || {};
+    for (var templateName in rawTemplates) {
+      if (rawTemplates.hasOwnProperty(templateName)) {
+        if (!extraTemplates[templateName]) extraTemplates[templateName] = this.compile(rawTemplates[templateName]);
+      }
+    }
   }

   HoganJsUtils.prototype.render = function(namespace, view, params) {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 3bb754ac..a34839c0 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -36,7 +36,7 @@ describe('HoganJsUtils', function() {
       assert.equal(null, result);
     });

-    it('should allow templates to be overridden', function() {
+    it('should allow templates to be overridden with compiled templates', function() {
       var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');

       var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
@@ -44,5 +44,27 @@ describe('HoganJsUtils', function() {
       var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
       assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
     });
+
+    it('should allow templates to be overridden with uncompiled templates', function() {
+      var emptyDiffTemplate = '&lt;p&gt;&lt;/p&gt;';
+
+      var config = {rawTemplates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
+
+    it('should allow templates to be overridden giving priority to compiled templates', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+      var emptyDiffTemplateUncompiled = '&lt;p&gt;Not used!&lt;/p&gt;';
+
+      var config = {
+        templates: {'generic-empty-diff': emptyDiffTemplate},
+        rawTemplates: {'generic-empty-diff': emptyDiffTemplateUncompiled}
+      };
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is how you can display code diffs]]></summary></entry></feed>