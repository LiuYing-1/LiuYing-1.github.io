<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://liuying-1.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://liuying-1.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-08T14:41:57+00:00</updated><id>https://liuying-1.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Concourrency 1</title><link href="https://liuying-1.github.io/blog/2022/concurrency/" rel="alternate" type="text/html" title="Concourrency 1"/><published>2022-12-30T10:43:00+00:00</published><updated>2022-12-30T10:43:00+00:00</updated><id>https://liuying-1.github.io/blog/2022/concurrency</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/concurrency/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/EFRqraM.png" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <div align="right"><i>Reference: This note is based on the Course Advanced Computer Systems from UCPH</i></div> <h3 id="do-it-yourself-recap">Do-it-yourself Recap</h3> <p><strong>Techniques for Performance</strong></p> <p><em>What is the meaning of the following performance metrics: throughput, latency, overhead, utilization, and capacity?</em></p> <p><em>Why can concurrency improve throughput and latency? How is that related to modern hardware characteristics?</em></p> <p>Separate the processing of signal requests, and put a process into different requests in parallel as well =&gt; Improve throughput</p> <p>We reduce the number of things that need to be executed sequentially. We may not reduce the latency of a single request, but on average, it improves the latency.</p> <h3 id="objectives-today">Objectives Today</h3> <ol> <li>Identify the multiple interpretations of the property of atomicity. =&gt; Talk about atomicity as a <em>desirable</em> property of a system that uses concurrency to optimize for performance.</li> <li>Implement methods to <em>ensure before-or-after atomicity</em>, and argue for their correctness. =&gt; When talking before or after atomicity, 2 basic strategies for achieving it are considered, <em>lock</em> and <em>lockless</em>.</li> <li>Explain the variants of the two-phase locking (2PL) protocol, particularly the widely-used Strict 2PL.</li> <li>Explain situations where predicate locking is required.</li> <li>Discuss the definition of serializability and the notion of anomalies (that do not happen for serializable executions).</li> </ol> <h3 id="read-write-systems">Read-Write Systems</h3> <p>In general, we will look at Read-Write Systems when we could say we are <strong><em>operating against the memory abstraction or we are trying to speed up the memory abstraction by concurrency</em></strong> and we want to still <strong><em>have some guarantees about the computations</em></strong>. We do not want to leave the actions of the concurrent to execute arbitrarily but we want to put some restrictions on those. And the core idea is to <strong><em>group the individual actions</em></strong> that we want to interleave or not interleave in the transactions. So that is <strong><em>On-Line Transaction Processing</em></strong> (OLTP). We have processing not only read and write actions but groups of those and grouped into transactions. Such systems do these operations and group them into transactions that arise all over the place.</p> <p><strong>Process multiple, but relatively simple, application functions</strong></p> <p><strong>Examples</strong> Distributed</p> <p>Order processing, e.g., Amazon</p> <p>Item buy/sell in computer games, e.g., EVE online</p> <p>High-performance trading</p> <p>Updates on social networks, e.g., Facebook</p> <h3 id="transaction">Transaction</h3> <p><b>In this course, we would like to focus more on the relationship between Abstractions and Performance, and to improve Performance, we can use concurrency which has ensured the property of Atomicity.</b></p> <p><strong>Transaction</strong> is a group of certain smaller actions but from a high level, it is a reliable unit of work against memory abstraction. Particularly, this is a unit of work that does some reads and rights.</p> <p>In this course, we consider memory abstraction with a database, as it is the original thing to have these four properties. In reality, memory abstraction goes beyond the databases, namely, the <strong>ACID</strong> properties go beyond just the databases.</p> <p><strong>ACID Properties</strong></p> <ul> <li><strong>Atomicity</strong>: transactions are <strong>all-or-nothing</strong></li> <li><strong>Consistency</strong>: a transaction takes the database <strong>from one consistent state to another</strong></li> <li><strong>Isolation</strong>: transaction executes as if it were the only one in the system (aka before-or-after atomicity)</li> <li><strong>Durability</strong>: once the transaction is done (“committed”), results are persistent in the database</li> </ul> <h3 id="examples-of-transactions-in-sql-bank-transfers">Examples of Transactions in SQL (Bank Transfers)</h3> <p>Under the hood, we know it all translates to calls to <code class="language-plaintext highlighter-rouge">READ</code> and <code class="language-plaintext highlighter-rouge">WRITE</code>.</p> <h3 id="conceptual-model---version-histories">Conceptual Model - Version Histories</h3> <p>Conceptually, we think of a system that executes transactions as having certain versions. For example, if we do a transaction of transfer, then, we might have one version of the database.</p> <h3 id="the-many-faces-of-atomicity">The many faces of atomicity</h3> <p>The definition of <strong><em>atomicity</em></strong> is a strong modularity mechanism, it can hide that one high-level action is actually made of many sub-actions. For example, if you have a lot of sub-actions and make them together by using atomicity, then, even though you talk to these sub-actions, it is equivalent to talking to the high-level one action because of the <strong><em>atomicity</em></strong>.</p> <p>However, the above is not what we are talking about here. We prefer to talk to the following two.</p> <p><strong>Before-or-after</strong> atomicity == isolation: =&gt; Cannot have effects that would only arise by an interleaving of parts of transactions.</p> <p><strong>All-or-nothing</strong> atomicity == atomicity + durability: =&gt; Must be fully executed and once executed and committed, they are durable or they should be rolled back or aborted.</p> <p><i>Official Statement: Cannot have partially executed transactions; once executed and confirmed, transaction effects are visible and not forgotten</i></p> <p>Today, we are going to focus on <b>Before-or-after</b> atomicity.</p> <h3 id="scale-up">Scale Up</h3> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/wVp3U3t.png" alt="image-20221230154333333" style="zoom:50%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>This is the simplistic view of the machine, we need to use concurrency to scale it up. Before we talk about concurrency, we can capable to extend it to multiple disks which provide a consistent data state (RAID systems). We will not talk about it here, just a blue picture. Then, we extend the CPU into multiple CPUs with more concurrent resources. And we need to ensure that the <strong>ACID</strong> properties are still there and this is the task of concurrency control.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/S4ISHW1.png" alt="image-20221230155236297" style="zoom:33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>The problem we are solving is we want to automatically make sure despite running and executing the transactions concurrently that the <strong><em>before-or-after atomicity is ensured</em></strong>.</p> <h3 id="goal-of-concurrency-control">Goal of Concurrency Control</h3> <p>Transactions should be executed so that it is as though they are executed in some serial order. Also called <strong>Isolation</strong> or <strong>Serializability</strong> or <strong>Before-or-after</strong> atomicity. However, this is not easy to achieve and comes with a certain overhead. So, there are some weaker variants. Weaker variants are also possible, they are about a lower “<strong>degree of isolation</strong>”. Below we are going to talk about several different degrees of isolation.</p> <p><strong>Bank Example</strong></p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/GuWyG6f.png" alt="image-20221228164315658" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>What we mean by serial execution is that T1 should occur with T2 or vice versa. Should occur before T1 so we want to execute these transactions and we don’t care how we execute how we split them out for the interleave of the transactions, but the overall net effect of executing these transactions should be as if either T1 executed first, then T2 executed or the opposite direction T2 get first and T1.</p> <p><i>Official Statement: If submitted concurrently, net effect should be equivalent to Xacts running in some serial order. No guarantee that T1 logically occurs before T2 (or vice-versa) - but one of them is true.</i></p> <h3 id="solution-1">Solution 1</h3> <p>The first solution is not use concurrency. Just get exclusive lock on entire database =&gt; Execute the entire transaction and then release exclusive lock. Hence, only one transaction can access the database at the time. Serializability guarantee because execution is serial!</p> <p>The problem is obviously no concurrency and it cannot achieve our goal of executing the transactions quickly.</p> <h3 id="solution-2">Solution 2</h3> <p>Get exclusive locks on <em>accessed</em> data items. Execute the transaction and release exclusive locks. For example, some transaction will access accounts of A and B, so it will get locked on these accounts. Then execute the transaction and then release the exclusive locks. This is greater concurrency. So, if the two transactions do not access the same data item, they can interact execute concurrently.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/jwM83yW.png" alt="image-20221230164306540" style="zoom:50%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>In this solution, we grab all the locks we will need, and then, in the end, we release them at once.</p> <p>However, it does not work for our mentioned example. If two transactions access the same data item, there will be no concurrency here, they will be executed serially.s</p> <h3 id="solution-3-cs2pl">Solution 3 CS2PL</h3> <p>Let’s make it be more relax.</p> <p>Get exclusive locks on data items that are <strong><em>modified</em></strong> and get shared locks on data items that are only <strong><em>read</em></strong>. Execute the transaction, and then, release all locks.</p> <p>Multiple people can have a shared lock and simultaneously read from the same object that the lock. If you have an exclusive lock and someone tries to get a shared lock. This will not be allowed.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/WFlGt7F.png" alt="image-20221230164902936" style="zoom:50%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>We refine slightly the kind of locks that we are using and in fact, it’s already not too far from practice. =&gt; Conservative strict two-phase locking.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/jwM83yW.png" alt="image-20221230164306540" style="zoom:50%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>The problem is that it can still not be concurrent with our example as in our example, there are two modification actions in two transactions.</p> <h3 id="solution-4-c2pl">Solution 4 C2PL</h3> <p>Get exclusive locks on data items that are modified and get shared locks on data items that are read.</p> <p>Execute transactions and release locks on objects no longer needed during execution. =&gt; <em>Release locks during execution</em>.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/BW1nljD.png" alt="image-20221230165613638" style="zoom:50%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>We are not releasing the locks only at the end of the transaction but releasing that gradually. =&gt; More concurrency as now other transactions can grab those locks that have been released earlier.</p> <p><strong>Problem here</strong></p> <p>It is very hard to roll back. Think of multiple transactions and suppose one transaction runs then it releases a lock for an object that has modified. So another transaction can start accessing this lock. Now, if the first transaction for some reason needs to abort and we would like to undo the changes it performed. We also need to abort the second transaction because the second transaction has already seen the modification by the first transaction that will not be part of. =&gt; <strong><em>Cascading</em></strong>. The abort of one transaction will cause potentially false aborts of the other transactions.</p> <p>Conservative refers to the left side of this picture where we at the beginning grab all locks at once.</p> <h3 id="solution-5-s2pl">Solution 5 S2PL</h3> <p>Get exclusive locks on data items that are modified and get shared locks on data items that are read, but do this during the execution of the transaction (as needed). Release all locks.</p> <p>We don’t get all the locks at the beginning, we rather start executing and when we need to access something, we try to get a lock. But we do release all the locks at once in the end. =&gt; <strong><em>Strict Two Phase Locking (S2PL)</em></strong></p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/oOrO61h.png" alt="image-20221230171004331" style="zoom:50%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>The problem is if T1 requests for A’s lock, while T2 requests for B’s lock, and then, they just keep waiting and block each other to get the locks. =&gt; <strong><em>Deadlock</em></strong>.</p> <h3 id="solution-6-2pl">Solution 6 2PL</h3> <p>Get exclusive locks on data items that are modified and get shared locks on data items that are read, but do this during the execution of the transaction (as needed).</p> <p>Release locks on objects no longer needed during the execution of the transaction.</p> <p><strong><em>Cannot acquire locks once any lock has been released, hence two-phase (acquiring phase and releasing phase)</em></strong></p> <p>Gives more concurrency however we also suffer more problems, it has more problems with deadlocks and the cascading.</p> <h3 id="summary-of-alternatives">Summary of Alternatives</h3> <p><strong>CS2PL</strong> No deadlocks, no cascading aborts, but need to know objects a priori, <strong>least concurrency</strong></p> <p><strong>C2PL</strong> No deadlocks, more concurrency than <strong>CS2PL</strong>, but need to know objects a priori, when to release locks <strong>cascading aborts</strong></p> <p><strong>S2PL</strong> No cascading aborts, <u>no need to know objects a priori or when to release locks</u>, more concurrency than <strong>CS2PL</strong>, but <strong>deadlocks</strong></p> <p><strong>2PL</strong> Most concurrency, no need to know objects a priori, but need to know when to release locks, cascading aborts, deadlocks =&gt; 2PL has all the kind of worst problems</p> <p>According to the summary, we need to pick one of them to be the main approach to ensure atomicity. From the perspective of the realistic meaning, CS2PL is not a suitable approach as it is the least concurrency. Additionally, during the execution of the transactions, it is not easy to know the objects you need in advance and this will be a downside. Hence, we select <strong>S2PL</strong> to focus on and address the problems.</p> <h3 id="reason-for-choice-s2pl">Reason for choice S2PL</h3> <p>Cannot know objects a priori, so no Conservative options =&gt; only if you would know something about the application!</p> <p>Thus only 2PL and S2PL left</p> <p>2PL needs to know when to release locks (main problem), and has cascading aborts</p> <p>Hence S2PL</p> <p><strong>Thus, what we need to do is deal with deadlocks.</strong> =&gt; S2PL’s problem</p> <h3 id="lock-management">Lock Management</h3> <p>Typically our system has a lock manager and we do not technically implement it, we just request an exclusive/shared lock. <em>Lock/Unlock requests handled by the lock manager.</em></p> <p><strong>Lock table</strong> entry:</p> <ol> <li>Number of transactions currently holding a lock =&gt; Which transaction currently holds locks</li> <li>Type of lock held (shared or exclusive)</li> <li>Pointer to the queue of lock requests</li> </ol> <p>Locking and unlocking have to be atomic operations =&gt; Have to be in composable units.</p> <p>Lock <strong>upgrade</strong>: a transaction that holds a shared lock can be upgraded to hold an exclusive lock.</p> <h3 id="dynamic-databases---locking-the-objects-that-exist-now-in-the-database-is-not-enough">Dynamic Databases - Locking the objects that exist now in the database is not enough</h3> <p>The protocols (except <strong><em>Solution 1</em></strong>) which are mentioned above have the limitations that the databases are fixed, for example, the number of records should be fixed at least.</p> <p>If we relax the assumption that the DB is a fixed collection of objects, even Strict 2PL will not work correctly。</p> <p>The fundamental assumption for all these project protocols is that we <strong>are not extending the objects</strong>.</p> <h3 id="the-problem">The Problem</h3> <p>To address the problem mentioned above, we need some mechanism to enforce the assumption and that is called <strong>index locking</strong> or <strong>predicate locking</strong>.</p> <p>The example shows that correctness is guaranteed for locking on individual objects <strong>only if the set of objects is fixed</strong>.</p> <h3 id="index-locking">Index Locking</h3> <p>If data is accessed by an <strong>index</strong> on the rating field, T1 should <strong>lock the index page</strong> containing the data entries with rating = 1. If there are no records with rating = 1, T1 must lock the index page where such a data entry would be, if it existed.</p> <p>If there is a lock on the index, this will mean that the index cannot be extended so transaction 2 will not be able simply not be able to add a new sailor (example) = wait for the lock to continue.</p> <p>If there is no suitable index, we need to lock all the pages and also the entire table to prevent new records can be added to this table.</p> <p>Hence, this is called index locking. <em>Predicate locking is a small generalization of index locking.</em></p> <h3 id="multiple-granularity-locks">Multiple-Granularity Locks</h3> <p>We have talked about locking the entire database and this is another refinement of the protocols that we looked at you can take locks at all these different levels and this will give you more fined gradient access to the data items that you need.</p> <p>In fact, the refinement consists of not only using the shared or exclusive locks for these different levels but also refining the kinds of locks that we are using. So the idea somehow is we don’t want to decide precisely what to lock. We want to lock the containers as we go from the outer layer. Data containers are nested.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/8bIF0Mt.png" alt="image-20230101143547555" style="zoom:50%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <h3 id="solution---new-lock-modes-protocol">Solution - New Lock Modes, Protocol</h3> <p>This is a new lock model that is used to extend the standard mode of excessive entry blocks with so-called intention locks.</p> <p>Allow transactions to lock at each level, but with a special protocol using new “intention” locks.</p> <p>Before locking an item, the transaction must set “intention locks” on all its ancestors.</p> <p>For unlock, go from specific to general (i.e., bottom-up).</p> <p>SIX mode: Like S &amp; IX at the same time.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/sStZ4yr.png" alt="image-20230101144336181" style="zoom:33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/ixOtbse.png" alt="image-20230101151354368" style="zoom:50%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>Firstly, T1 would like to read the table Emp, and then, it locks the entire dabase with IS and lock the table with S. After that, T2 comes in, it would like to modify the data item, hence, T2 locks the entire database with IX and the table with IX as T2 would like to modify the data item. However, it is not allowed that table Emp can hold S and IX at the same time. T2 wait for forward.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/S7Yr9D3.png" alt="image-20230101153220566" style="zoom:50%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <h3 id="is-s2pl-correct-assuming-database-is-not-dynamic">Is S2PL correct? (Assuming database is not dynamic)</h3> <p>We will formalize now and next class <strong>serializability</strong> and argue that S2PL is correct.</p> <p>S2PL can however deadlock. We will see how to handle deadlocks automatically.</p> <h3 id="schedules">Schedules</h3> <p>To talk about serializability, we need an notion of schedules.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/5GEzD1u.png" alt="image-20230101155626139" style="zoom:33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p><em>Each action has its own momentum time.</em></p> <h3 id="scheduling-transactions">Scheduling Transactions</h3> <ol> <li><strong>Serial schedule</strong>: Schedule that does not interleave the actions of different transcations.</li> </ol> <p><em>The two schedules are equivalent if they hold the following two poinst.</em></p> <ol> <li><strong>Equivalent schedules</strong>: For any database state, =&gt; 输入输出完全一样，只不过操作顺序不一样</li> </ol> <ul> <li> <p>The effect (on the set of objects in the database) of executing the schedules is the same.</p> </li> <li> <p>The values read by transactions is the same in the schedules</p> <ul> <li>assume no knowledge of transaction logic.</li> </ul> </li> </ul> <ol> <li><strong>Serializable schedule</strong>: A schedule that is equivalent to some serial execution of the transactions.</li> </ol> <p>我的理解是如果一个调度没有交互事件的话，则是1，如果此时有另一个调度，每一时刻的输入和输出和最初的调度完全一样，那么新的调度和原先的调度等价且是serializable的。</p> <p>(Note: If each transaction preserves consistency, every serializable schedule preserves consistency)</p> <h3 id="anomalies-with-interleaved-execution-3">Anomalies with Interleaved Execution 3</h3> <ol> <li> <p>Write-Read Conflict</p> <p>The transaction reads data that is not committed. =&gt; Reading Uncommitted Data (WR Conflicts, “dirty reads”)</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/yBFkzPH.png" alt="image-20221228164315658" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>但是如果abort是commit，那就没事，这个调度会是serializable schedule.</p> </li> <li> <p>Read-Write Conflict</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/uEtwoSg.png" alt="image-20221228164315658" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>同一个事件里，读取了同一个数据A，但是由于T2读了A并且更改了A的值并且提交了，所以T1再读A的值变得不一样，所以T1就不知道该用哪个A。如果没有提交的话，就是脏读。</p> <p>Just observe two reads of the same object that results in different values like a transaction must be able to rely on the property that if it reads the same object multiple times without itself writing to it then it should see the same values.</p> </li> <li> <p>Write-Write Conflict</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/Px0NhvF.png" alt="image-20221228164315658" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>What is the state in the end? The value of A is the one written by T2 and the value of b is the one written by T1, and this is not equivalent to any serial execution.</p> </li> </ol> <h3 id="final-summary">Final Summary</h3> <ul> <li>Identify the multiple interpretations of the property of atomicity</li> <li>Implement methods to ensure before-or-after atomicity, and argue for their correctness.</li> <li>Explain the variants of the two-phase locking (2PL) protocol, in particular the widely-used S2PL</li> <li>Explain situations where predicate locking is required</li> <li>Discuss the definition of serializability and the notion of anomalies</li> </ul>]]></content><author><name>Ying Liu</name></author><category term="study"/><category term="ucph"/><category term="acs"/><summary type="html"><![CDATA[This is the chapter relating to concurrency control.]]></summary></entry><entry><title type="html">Incorrect URL</title><link href="https://liuying-1.github.io/blog/2022/incorrect-url/" rel="alternate" type="text/html" title="Incorrect URL"/><published>2022-12-29T23:37:37+00:00</published><updated>2022-12-29T23:37:37+00:00</updated><id>https://liuying-1.github.io/blog/2022/incorrect-url</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/incorrect-url/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> &lt;img src="https://i.imgur.com/U8zSWGe.jpeg" alt="nerd" class="img-fluid rounded z-depth-1" data-zoomable %} </div> </div> <p>I was interested to my neighbor’s puzzle as the clue to find his gift is like something related to IT. It was about to route to the web page based on the given URL. However, it does not work as the routed page always responded like “Sorry, your request does not exist”. I was also tried to figure it out, but the result was also failure.</p> <p>After mins, some other neighbor just recognized that what we need is to sign in with our account to enjoy the service. The picture was photoed to prove the “Incorrect URL Verified by Code Nerd”.</p>]]></content><author><name></name></author><category term="daily-life"/><category term="fun"/><summary type="html"><![CDATA[Last time, my neighbor, whose world ranking in CSGO is the Global Elite, received a Christmas gift by his nisse.]]></summary></entry><entry><title type="html">Godt Nytår</title><link href="https://liuying-1.github.io/blog/2022/godt-nytar/" rel="alternate" type="text/html" title="Godt Nytår"/><published>2022-12-29T23:37:37+00:00</published><updated>2022-12-29T23:37:37+00:00</updated><id>https://liuying-1.github.io/blog/2022/godt-nytar</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/godt-nytar/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/YfD5KLi.jpeg" alt="godt-nytar" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <p>Last night, our kitchen celebrated the coming new year together. We listened to the Queen’s Speech, Ate the Starter (Salmon and Cod Fish Salad), Dumplings (Made by Me), Baked Celery for the main course. Finally, we witnessed the firework on the top floor of the Tietgenkolleigiet.</p>]]></content><author><name></name></author><category term="daily-life"/><category term="fun"/><summary type="html"><![CDATA[The blog is to record my first New Year's Eve in Denmark!]]></summary></entry><entry><title type="html">RPC | Performance</title><link href="https://liuying-1.github.io/blog/2022/rpc/" rel="alternate" type="text/html" title="RPC | Performance"/><published>2022-12-28T14:39:00+00:00</published><updated>2022-12-28T14:39:00+00:00</updated><id>https://liuying-1.github.io/blog/2022/rpc</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/rpc/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/irOrf0o.png" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <h3 id="fundamental-abstractions">Fundamental abstractions</h3> <p><strong>Which were the three fundamental abstractions?</strong></p> <p>Memory abstraction, interpreter abstraction, and communication link abstraction.</p> <p><strong>What were their APIs?</strong></p> <p><code class="language-plaintext highlighter-rouge">Memory -&gt; READ(Name) \ WRITE(Name, Value)</code></p> <p><code class="language-plaintext highlighter-rouge">Interpreters -&gt; loop(print(eval(read)))</code></p> <p><code class="language-plaintext highlighter-rouge">Communication links -&gt; SEND(linkName, ourgoingMessageBuffer), RECEIVE(linkName, incomingMessageBuffer)</code></p> <p><strong>Must these abstractions be implemented in a single node or can they be distributed? Give an example.</strong></p> <p>Yes. For memory, the key-value storage is a distributed example.</p> <h3 id="what-should-we-learn-today">What should we learn today?</h3> <h4 id="interpreter">Interpreter</h4> <p>There is one kind of interpreter one own layered program! (RPCs)</p> <h4 id="layers-and-modules">Layers and Modules</h4> <p><strong>Why do we need layers and modules?</strong></p> <p>Interpreters are often organized in layers.</p> <p>Modules: Components that can be separately designed/implemented/replaced. “Instructions” of higher-level interpreters. Recursive: can be whole interpreters themselves!</p> <p>Example:</p> <p><strong>Twitter</strong></p> <p>If the user is tweeting away, the whole server plus the front end is sort of an interpreter. As the user gives the input, then, it gives you a set of commands to work with to play this.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/0g4utKy.png" alt="image-20221228153845633" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>Of course, first, you know this is not the single program that is running when you interact in this Twitter assets and entire layouts services and complications and all of these services have their own set of commands and old language that they understand and in the sense. <strong><em>Twitter is the entirety of these multiple interpreters structured together in a hierarchical way.</em></strong></p> <p>Continued example: Normally, the website may be Facebook, has a lot of components that implement very different algorithms and somehow need to interact with each other the main thing you want to avoid when building the system is the failure of one component, let’s say the component of all such services failure of this component should not bring down the entire system. We want to isolate failures and make the entire system fault-tolerant. So, how can we isolate errors?</p> <h4 id="isolating-errors---enforced-modularity">Isolating Errors - Enforced Modularity</h4> <p>The basic idea of isolating errors is to use clients and services.</p> <p>One way to separate concerns. <strong><em>Restrict the communication to messages only</em></strong>, <strong><em>Client request/Service respond (or reply)</em></strong>, <strong><em>Conceptually client and service in different computers</em></strong></p> <p>The other way to separate concerns is to further sandbox these applications into different parts of the operating system so that they definitely cannot interact with each other as memory, even if they are running on the same machine, this is called virtualization so that it contains the components into sandboxes where they cannot harm anyone outside of the sandbox.</p> <p>The above two techniques are very normal to use. In this course, we would talk more about <em>Remote Procedure Call (RPC)</em>.</p> <h4 id="rpc---remote-procedure-call">RPC - Remote Procedure Call</h4> <p>WebService is a very good example to apply RPC.</p> <p>RPC is a way for <strong><em>clients and services to communicate with each other</em></strong>. Maybe breaking slightly the abstraction that <strong><em>communication only works by messages</em></strong>. RPC <strong><em>pretends that the two applications do run on the same computer</em></strong> even though in reality they don’t but they try to <em>hide the fact that messages are being sent over the network from the developers from these applications</em> (not fully understood here).</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/6qVZA6T.png" alt="image-20221228164315658" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>Here is a good explanation of RPC in Chinese. Referenced Here: https://www.jianshu.com/p/7d6853140e13. <a href="https://en.wikipedia.org/wiki/Marshalling_(computer_science)">Wikipedia Definition of Marshall</a></p> <p><a href="https://zhuanlan.zhihu.com/p/187560185">The other explanation for RPC</a></p> <hr/> <p>In the context of RPC, a stub is <strong><em>a piece of code that acts as a client for remote service</em></strong>. It is responsible for <strong><em>marshaling (converting) the parameters of the call into a format that can be transmitted over the network to the remote service, and for unmarshalling (converting) the results of the call back into a form that can be understood by the calling program</em></strong>.</p> <p><strong><em>Stubs</em></strong> are used in RPC to allow client programs to call remote functions as if they were local, without having to worry about the details of network communications or the implementation of the remote service. This makes it easier to write distributed applications that can make use of services provided by other programs on different machines.</p> <p>My understanding is, first of all, the <strong><em>aim of RPC is to call the services of a remote server as if it were a local function</em></strong>. The client calls a remote function which is <code class="language-plaintext highlighter-rouge">GET_CONNECTIONS(uid)</code> which has been mentioned above, then, the client part calls the local (client) stub, which will then <strong><em>package (Marshall) the parameters of the function call into a message and send it over the network to the server</em></strong>. The server will receive the message and the server stub will unpackage the marshaler requests. Then execute the requested function, and return the results back after the service stub marshaled reply, to the client in the form of another message. The client’s stub will then receive this message, extract the results, and pass them back to the calling program.</p> <font color="red">**Difference between RPC and local procedure call** and what can go wrong when a client crashes? What about when a server crashes?</font> <ol> <li>By using RPC, the probability of failure occurs that brings down the whole system gets reduced as they are individuals.</li> <li>RPC has longer latency.</li> <li>RPC introduced a new failure mode which is “no-response”.</li> <li>Some programming languages will not fit well or work well with RPC mode.</li> </ol> <h4 id="rpc-semantics">RPC semantics</h4> <p>Even though we can use the method <code class="language-plaintext highlighter-rouge">timeout</code> to address the case of no response for a service, it is useless sometimes as what we can know from it is only there is something wrong with when performing the service. Hence, we still have some other approaches to address no-response cases.</p> <p><strong>At-least-once</strong> (Because the functions are pure, it is no worry to think about whether they will cause any side effects. Hence, keep sending the requests, at least receive one or more than one response.)</p> <p><em>Operation is idempotent</em>. Naturally occurs if side-effect free</p> <p>Stub just retries the operation -&gt; failures can still occur!</p> <p>Example: calculate <code class="language-plaintext highlighter-rouge">SQRT</code></p> <p><strong>At-most-once</strong> (It is possible to set the timeout of the service when there is no response to the client, the server replies to the error to the client, and then, the money may or may not be there. We do not need to send requests anymore.)</p> <p>Operation does have side-effects</p> <p>Stub must ensure duplicate-free transmission</p> <p>Example: transfer $100 from my account to yours</p> <p><strong>Exactly-once</strong> (Ideal case, impossible to implement.)</p> <p>Possible for certain classes of failures</p> <p>Stub &amp; service keep track (<em>durably</em>) of requests and responses</p> <p>Example: bank cannot develop amnesia!</p> <h4 id="rpc-and-naming">RPC and Naming</h4> <p>Typically, we need to take care of the naming when using the RPCs. We want to know where the service sits and normally there is standard integration with the name of the directory service.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/98PAbLE.png" alt="image-20221228191230123" style="zoom:33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>The server first registers the service with a name into the directory service. Then, the client will look up where the service sits. The directory service will return an address to the client. Then send the request with the received address and get the response.</p> <p><strong>Advantages</strong></p> <ol> <li> <p>The directory for dev can be independent of the directory for deployment.</p> </li> <li> <p>more flexible as if one of the services failed, then go to the directory to find the alternatives.</p> </li> <li> <p>This directory can get extended, for example, DNS can host more than one record.</p> </li> </ol> <h4 id="rpcs-over-http"><font color="red">RPCs over HTTP</font></h4> <p>Scenario: Services are widely exposed on the web, accessible via HTTP.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/y7XLxDj.png" alt="image-20221228191820827" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p><strong>Why is this a good idea?</strong></p> <p><strong>Discuss how the following features of HTTP affect service interfaces, if at all:</strong></p> <p><em>Proxies</em>: Country Security, A good design should confine the message transmitted in a specific area.</p> <p><em>Persistent connections</em>: The duplicated authentication is not needed, the service can focus on its service.</p> <p><em>Caching</em>: Similar to the part of memory (RAM). The cache stores the most popular requests and the answers, then it can reply to the clients faster.</p> <h4 id="common-issues-in-designing-services">Common Issues in Designing Services</h4> <p><strong>Consistency</strong></p> <p>How to deal with updates from multiple clients?</p> <p><strong>Coherence</strong></p> <p>How to refresh caches while respecting consistency?</p> <p><strong>Scalability</strong></p> <p>What happens to resource usage if we increase the #clients or the #operations?</p> <p><strong>Fault Tolerance</strong></p> <p>Under what circumstances will the service be unavailable?</p> <h4 id="performance">Performance</h4> <h5 id="abstractions-implementation-and-performance">Abstractions, Implementation and Performance</h5> <p>Let I1 and I2 be two implementations of an abstraction</p> <p><strong>Examples</strong></p> <p>Web service with or without proxies</p> <p>Virtual memory with or without paging</p> <p>Transactions via concurrency or serialization</p> <p><em>So, how do we choose between I1 and I2?</em></p> <h5 id="performance-metrics">Performance Metrics</h5> <div align="center"><div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/gQDuiiG.png" alt="image-20221229170651060" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>What do these metrics mean?</p> <p><strong>Capacity</strong> is a consistent measure of a service’s size or amount of resources.</p> <p><strong>Utilization</strong> is the percentage of capacity of a resource that is used for some given workload of requests.</p> <p><strong>Overhead</strong> is any combination of excess or indirect computation time, memory, bandwidth, or other resources that are required to perform a specific task.</p> <p><strong>Latency</strong> is the delay between a change at the input to a system and the corresponding change at its output. From the client/service perspective, the latency of a request is the time from issuing the request until the time the response is received from the service.</p> <p><strong>Throughput</strong> is a measure of the rate of useful work done by a service for some given workload of requests. In the camera example, the throughput we might care about is how many frames per second the system can process because it may determine what quality camera we want to buy.</p> <p>How many operations the service can process in a given unit of time?</p> <p><strong>Example of Throughput</strong></p> <hr/> <p><em>Consider a computer system with two stages: one that is able to process data at a rate of 1,000 kilobytes per second and a second one at a rate of 100 kilobytes per second. If the fast stage generates one byte of output for each byte of input, the overall throughput must be less than or equal to 100 kilobytes per second. If there is negligible overhead in passing requests between the two stages, then the throughput of the system is equal to the throughput of the bottleneck stage, 100 kilobytes per second. In this case, the utilization of stage 1 is 10% and that of stage 2 is 100%.</em></p> <p><em>When a stage processes requests serially, the throughput and the latency of a stage are directly related. The average number of requests a stage handles is inversely proportional to the average time to process a single request:</em></p> \[throughput = \frac{1}{latency}\] <p>However, it does not hold when there is concurrency. It only works on only single thread.</p> <hr/> <p><strong>Scalability</strong> is the measure of a system’s ability to increase or decrease in performance and cost in response to changes in application and system processing demands. Examples would include how well a hardware system performs when the number of users is increased, how well a database withstands growing numbers of queries, or how well an operating system performs on different classes of hardware. Enterprises that are growing rapidly should pay special attention to scalability when evaluating hardware and software.</p> <h4 id="common-issues-with-performance-metrics">Common Issues with Performance Metrics</h4> <p><strong>Properties of resources and/or services</strong></p> <ol> <li> <p><strong>Utilization, Capacity</strong></p> <p>How many requests or how many ports can be accepted or held? =&gt; Capacity</p> </li> <li> <p><strong>Overhead, throughput, latency</strong></p> </li> <li> <p><strong>Scalability</strong></p> </li> </ol> <p><strong>Considering scalability alone is dangerous.</strong></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/irOrf0o.png" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <p>Here is an example that choosing B might be the best option.</p> <h4 id="riding-moores-law">Riding Moore’s Law</h4> <p>CPU clock speed does not get better anymore.</p> <p>Memory size, Memory bandwidth, disk size, and disk bandwidth are still improved a lot (50%), while memory latency (1%) and disk latency go slower (10%).</p> <h4 id="performance-and-hardware-trends">Performance and Hardware Trends</h4> <div align="center"><div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/7eRRg3q.png" alt="image-20221229175058392" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <div align="center"><div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/D0qVqcT.png" alt="image-20221229180314186" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <div align="center"><div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/fjXnqkv.png" alt="image-20221229180225002" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>This is very close to the real computer. Hence, we need to think about how to make the most usage of hardware like cache.</p> <h4 id="storage-hierarchy">Storage hierarchy</h4> <div align="center"><div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/whMAqED.png" alt="image-20221229180640710" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>The ratios between different levels of storage (memory) are not changed that much, and if we access the RAM, it is extremely fast. Oppositely, if we access the disk, it takes a quite long time.</p> <p><strong>What does that do to random access?</strong></p> <p>Actually what we call <strong>R</strong>andom <strong>A</strong>ccess <strong>M</strong>emory actually behaves as <strong>N</strong>ot-<strong>Q</strong>uite-<strong>S</strong>o-<strong>R</strong>andom <strong>A</strong>ccess <strong>M</strong>emory because of the memory hierarchy. Access to a nearby cell is <strong>much faster</strong> than to a faraway cell.</p> <h4 id="general-techniques-to-improve-performance">General Techniques to improve performance</h4> <p>If considering the clients and services architecture, fast-path coding will be one way. A designer may observe that certain requests are more common than other requests, and use that observation to improve the performance of frequent operations by splitting the staged pipeline into a fast path for frequent requests and a slow path for other requests.</p> <h5 id="fast-path-coding">Fast-path Coding</h5> <p><strong>Fast-path coding</strong> splits processing into two code paths.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/lSBnydN.png" alt="image-20221229182415410" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p>One optimized path for common requests is a <strong>fast path</strong>.</p> <p>One slow but comprehensive path for all other requests is a <strong>slow path</strong>.</p> <p><strong>Caching</strong> is an example of fast-path coding.</p> <h5 id="batching">Batching</h5> <p>It runs multiple requests at once. Collect requests and execute them only once. Batch-I/Os is a good example of batching with the Elevator algorithm. It may improve latency and throughput.</p> <p>批处理是指计算机用来周期性地完成大量重复数据作业的方法。某些数据处理任务（如备份、筛选和排序）可能需要大量计算，而且在单个数据事务上运行效率很低。相反，数据系统通常可以在计算资源更普遍可用的非高峰时间批量处理这些任务，例如一天结束时或夜间。例如，考虑一个全天接收订单的电子商务系统。系统可能会在每天结束时收集所有订单，并用一个批处理与订单履行团队共享，而不是在发生时处理每个订单。</p> <p><em>Reference: https://aws.amazon.com/cn/what-is/batch-processing/</em></p> <h5 id="dallying">Dallying</h5> <p>It is delaying a request on the change that the operation won’t be needed, or to create more opportunities for batching. For example, a stage may delay a request that overwrites a disk block in the hope that a second one will come along for the same block. If a second one comes along, the stage can delete the first request and perform just the second one. As applied to writes, this benefit is sometimes called write absorption.</p> <p>Dallying also increases the opportunities for batching. It purposely increases the latency of some requests in the hope that more requests will come along that can be combined with the delayed requests to form a batch. In this case, dallying increases the latency of some requests to improve the average latency of all requests.</p> <p>A key design question in dallying is to decide how long to wait. There is no generic answer to this question. The costs and benefits of dallying are application and system specific.</p> <p>Typical Example: <strong>Group Git</strong></p> <h5 id="parallelism">Parallelism</h5> <p>Increase the performance of hardware and the number of cores.</p> <h5 id="concurrency">Concurrency</h5> <p>Run multiple requests in different threads</p> <p><strong>Example</strong>: different web requests run in different threads or even servers</p> <p>May improve both throughput and latency, but must be careful with locking correctness.</p> <h5 id="speculation">Speculation</h5> <p>Predict the future. Guess the next requests and run them in advance. Prefetching is an example. May overlap expensive operations, instead of waiting for their completion.</p>]]></content><author><name>Ying Liu</name></author><category term="study"/><category term="ucph"/><category term="acs"/><summary type="html"><![CDATA[RPC and Permance are the two topics we will cover today.]]></summary></entry><entry><title type="html">Abstractions</title><link href="https://liuying-1.github.io/blog/2022/abstractions/" rel="alternate" type="text/html" title="Abstractions"/><published>2022-12-27T19:37:00+00:00</published><updated>2022-12-27T19:37:00+00:00</updated><id>https://liuying-1.github.io/blog/2022/abstractions</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/abstractions/"><![CDATA[<div align="center"> <div class="row mt-3 mb-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/abstractions.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <h1 id="why-study-big-computer-systems">Why study (big) computer systems?</h1> <p>“<em>How can I program large systems with clean interfaces and high performance?</em> “</p> <div align="right"><i>Microsoft/Oracle</i></div> <p><em>“How do I build systems to process TBs to PBs of data?”</em></p> <p>1TB = 1000GB, 1PB = 1000TB</p> <div align="right"><i>Cloudera/Teradata</i></div> <p><em>“How can I understand the guarantees and reliability of scalable services offered to me on the cloud?”</em></p> <p>How to ensure I am accessing my data, instead of others?</p> <div align="right"><i>Amazon/Google</i></div> <h4 id="what-is-the-scale-of-our-computer-systems">What is the scale of our computer systems?</h4> <p>According to the data in 2007, there is an increasing number of users and mountainous data for us to process. Building a system capable of processing such data is extremely demanding right now. To conclude with a specific example. How to build a trust-worthy “Facebook”?</p> <div align="center"><i><font color="red">How can we think about and architect large-scale computer systems? <b>Design</b> and <b>Build</b></font></i></div> <h4 id="what-should-we-learn-in-this-course">What should we learn in this course?</h4> <p><b>Knowledge</b></p> <p>Describe the <em>design of transactional and distributed systems,</em> including techniques for <em>modularity</em>, <em>performance</em>, and <em>fault tolerance</em>.</p> <p>Explain how to <em>employ strong modularity through a client-service abstraction</em> as a paradigm to structure computer systems, while <em>hiding the complexity of implementation from clients</em>.</p> <ul> <li>By implementing this, strong modularity will prevent the entire system down when a failure happens in a module or a component. How to achieve this principle by using client-service abstraction. Hide the complexity from the abstraction.</li> </ul> <p>Explain techniques for large-scale data processing.</p> <p><b>Skills</b></p> <p>Implement systems that include <u>_mechanisms for modularity, atomicity, and fault tolerance_</u>.</p> <p>Structure and conduct experiments to <em>evaluate a system’s performance</em>.</p> <p><b>Competences</b></p> <p>Discuss <em>design alternatives for a modular computer system</em>, identifying <em>desired system properties</em> as well as <em>describing mechanisms for improving performance</em> while arguing for their correctness.</p> <p>Analyze <em>protocols for concurrency control and recovery,</em> as well as for distribution and replication.</p> <p>Apply principles of large-scale data processing to analyze concrete information-processing problems. (Realize and build a model for addressing the future problem.)</p> <h4 id="what-will-we-study">What will we study?</h4> <p><strong>Topic 1:</strong> Strong Modularity</p> <ul> <li><strong>Fundamentals</strong> that build a system from the fundamentals. The property is <strong>Strong Modularity</strong>. <ol> <li>Abstractions: interpreters, memory, communication links. =&gt; Any large-scale systems that are built starting from the 3 fundamentals. They interacted with each other.</li> <li>Modularity with clients and services, RPC =&gt; Remote procedure calls</li> <li>Techniques for performance, e.g., concurrency, fast paths, dallying, batching, speculation</li> </ol> </li> </ul> <p>Strong modularity means <strong><em>building systems from components where the value of one component does not influence the rest of the system or does not severely influence the rest of the system</em></strong> maybe. Which has been mentioned above.</p> <p><strong>Topic 2</strong> Atomicity, Isolation, and Durability</p> <ul> <li> <p>Concurrency control and recovery</p> <p>One way to implement memory abstraction as is done is in large-scale database management systems. And they are about to achieve certain properties for this memory abstraction mainly atomicity isolation and durability. And the techniques to achieve them are concurrency control and recovery.</p> <p>Properties: <strong>Atomicity, Isolation, and Durability</strong>.</p> </li> <li> <p>Experimental design (Not the key points in this course)</p> <ol> <li>Performance metrics, workloads</li> <li>Structuring and conducting simple experiments</li> </ol> </li> </ul> <p><strong>Topic 3</strong> High Availability</p> <ul> <li> <p>Reliability &amp; Distribution</p> <p>Reliability means how we make sure if our system is built from a lot of components and the components I expected to fail. What are the best strategies to ensure that the system overall is available and achieves its goals?</p> </li> <li> <p>Communication</p> </li> <li> <p>Property: High Availability =&gt; we want our systems to be online all the time and the service should not be interrupted by a failure of small components.</p> </li> </ul> <p><strong>Topic 4</strong> Scalability with Data Size</p> <ul> <li> <p>Data processing</p> <p>More about algorithms and how to improve the performance with algorithms that implement parallelism.</p> </li> <li> <p>Property: Scalability with Data Size</p> </li> </ul> <hr/> <h3 id="what-should-we-learn-today">What should we learn today?</h3> <ul> <li> <p>Identify the fundamental abstractions in computer systems and their APIs, including memory, interpreters, and communication links.</p> <p>Fundamental abstractions allow us to break down a complex computer system into smaller pieces with a reasonable API that we can understand what it does no matter how complex the implementation of that API is.</p> <p>Specifically, we look at memory, interpreters, and communication links.</p> </li> <li> <p>Explain how names are used in the fundamental abstractions</p> <p>How these three fundamental abstractions work and communicate with names (APIs).</p> </li> <li> <p>Design a top-level abstraction, respecting its correspondent API, based on lower-level abstractions</p> </li> <li> <p>Discuss performance and fault-tolerance aspects of such a design.</p> </li> </ul> <h4 id="the-central-trade-off---abstractions-performance-fault-tolerance">The central Trade-off - Abstractions, Performance, Fault-Tolerance</h4> <p>When implementing a computer system, <strong>abstractions</strong> and <strong>performance</strong> and <strong>fault-tolerance</strong> are limited by each other. On the one hand, we would like to keep the clean interfaces so we need to have as simple components (abstractions). On the other hand, we still need to get the most use of performance which means we need to break the abstractions. Hence, we need to find ways where abstractions are sensible barriers that do not end up performance. Then, the final part is fault-tolerance.</p> <p>When introducing an abstraction, we will have a barrier between two components, and in particular, you will need to have a communication mechanism on this barrier. Hence, when introducing components, we increase the attack. (<font color="red">Not fully understood</font>)</p> <h4 id="fundamental-abstractions">Fundamental abstractions</h4> <p><strong>Memory abstraction</strong> <code class="language-plaintext highlighter-rouge">(Read/Write)</code></p> <p>A memory abstraction is something that allows you to read values and write values.</p> <p><strong>Interpreters abstraction</strong> <code class="language-plaintext highlighter-rouge">(loop(print(eval(read))))</code></p> <p>Have a set of commands that you can execute and the interpreter’s input instructions from somewhere else. They evaluate the instructions and print some output and continue this in a loop.</p> <p><strong>Communication links abstraction</strong> <code class="language-plaintext highlighter-rouge">Send/Receive</code></p> <p>It can be async and we don’t wait for the response or something like that.</p> <p><strong>Names</strong> make connections (glue) between these abstractions. Where do we read from or where do we write to? It can be any kind of format, e.g., addresses, IP addresses, web addresses, filenames, emails, telephone numbers, and so on.</p> <p>Sometimes, we call a name an address if it has some location information. <strong>Address is an overloaded name with location info. (e.g., LOAD 1742, R1)</strong>. The rest of the names require a mapping scheme to translate the original info into a fixed location. For example, a website is commonly associated with an IP address, and so on.</p> <h4 id="name-mapping">Name Mapping</h4> <p><strong>How can we map names?</strong></p> <p>We usually have some algorithms that take as input the names and some contexts and produce the addresses.</p> <p><strong><em>Type 1: Table lookup</em></strong> <em>Files inside directories.</em></p> <p>Typically, there will be something like a table lookup first so you could look up a file inside of a directory by taking the file name depending on the file system you are using, the precise lookup may look differently, but in practice, it translates to a table lookup or you can contact the DNS service to resolve the web address to an IP address. All these are called table lookups.</p> <p><strong><em>Type 2: Recursive lookup</em></strong> <em>Path names in file systems or URLs</em></p> <p>There might be some names structured with <code class="language-plaintext highlighter-rouge">/</code>, just like URLs, web addresses, or file paths. We need the recursive lookup or combine it with the table lookup to get to the location we are interested in.</p> <p><strong><em>Type 3: Multiple lookup</em></strong> <em>Java class loading</em></p> <p>When we code <code class="language-plaintext highlighter-rouge">Overloading</code> with Java, we might call a method in Java. This can be long multiple classes and you try to find or Java tries to find the best matching instance of the class to pick the implementation of the method you’re interested in. It is based on the types of objects involved.</p> <h4 id="memory-abstraction">Memory Abstraction</h4> <p><strong>API of the memory</strong></p> <p><code class="language-plaintext highlighter-rouge">READ(name) -&gt; value</code>: read from a name and obtain a value</p> <p><code class="language-plaintext highlighter-rouge">WRITE(name, value)</code>: where to write and which value to write</p> <p><strong>Examples of Memory</strong></p> <p><em>Physical memory is limited to the size of the RAM chip, virtual memory is limited by the size of the hard disk.</em></p> <p><em>RAM stores virtual addresses, while the disk stores physical addresses.</em></p> <p>Typically, when we are writing to the physical memory and our computer, we are using a physical address but typically we don’t address the RAM directly. But we work with a multi-level memory hierarchy that goes from memory that we can access quickly like the RAM.</p> <h4 id="how-would-you-design-a-two-level-memory-abstraction-consolidating-disk-and-ram">How would you design a two-level memory abstraction consolidating disk and RAM?</h4> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/SCFqonm.jpeg" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <p><br/> RAM is extremely expensive and it is volatile, but its speed is fast. While the Disk is in contrast that the price is very low and it is nonvolatile, however, it is high latency. Design top-level abstraction respecting <em>Memory API</em>.</p> <p><strong>Requirements below</strong></p> <ol> <li>Address as much data as fits in disk</li> <li>Use fixed-size pages for disk transfers</li> <li>Use RAM efficiently to provide for low latency (on average)</li> <li>Neither disk nor memory directly exposed, only <code class="language-plaintext highlighter-rouge">READ/WRITE</code> API.</li> </ol> <p><em>What does it mean to implement an abstraction? - What we need to do is implement the read and write functions and hide the two-level hierarcy to the users</em>.</p> <hr/> <p><strong>Proposal</strong> by the student</p> <p>Store both data in the RAM and disk. And always access the RAM first, if RAM finds the value, that’s good. When does not, then RAM would swap in the data from disk and to swap in RAM would use. Maybe at least recently use strategy to decide which page from the disk answer from the RAM to swap out.</p> <p>This is principal right, but an advanced version with smart data structures is below.</p> <p><strong>Hint</strong></p> <p>We have two address spaces, we have the addresses on the disk and addresses on the RAM. We need to bridge the gap between the two. So we introduce the naming scheme that operates with addresses of disk + RAM. So those are the virtual addresses and they give us as many addresses as we can access with the extraction. And we need to have something that translates these virtual addresses into concrete physical addresses. This could be a disk address or memory address. So the page map for example will have the virtual address, the page identifier and that will translate to the block number. Maybe on the disk first time I saw the block number memory. Let’s start with that.</p> <p>RAM stores most recently used pages and page map. <strong><em>Resident bit (R):</em></strong> access to non-resident pages results in page faults. <strong><em>Page fault</em></strong>:an indirection exception for missing pages.</p> <div align="center"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/O535uxz.jpeg" style="zoom: 33%;" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div> <hr/> <p><strong>How to handle the page faults?</strong></p> <p>Trap to OS handler and handler loads block from disk and updates mapping. If memory full, must choose some victim block for replacement. Page replacement algorithm, e.g., LRU.</p> <p>Other metadata: <strong><em>Dirty bit (D):</em></strong> Only write page back when it has changed! Pin bit (p): do not remove certain pages (e.g., code of OS handler itself)</p> <p><strong>Answer</strong></p> <p>To achieve this objective, we should put a page map recording <code class="language-plaintext highlighter-rouge">#Page</code>, <code class="language-plaintext highlighter-rouge">#Block</code>, <code class="language-plaintext highlighter-rouge">Pr</code>, <code class="language-plaintext highlighter-rouge">R</code>, <code class="language-plaintext highlighter-rouge">D</code> and <code class="language-plaintext highlighter-rouge">P</code> into the RAM, with some pages selected automatically which are mostly used recently by the computer. Then, when accessing a data. The computer system will access the RAM to lookup the table. Check whether the page is resident or not by verifing its <code class="language-plaintext highlighter-rouge">resident bit</code>. If value is <code class="language-plaintext highlighter-rouge">1</code>, then just get the data from the table which is already stored in the RAM. If not, check whether the RAM is full or not. If it is already full, apply LRU strategy to find out the record which is ready to replace. Then, check its <code class="language-plaintext highlighter-rouge">dirty bit</code> whether it is <code class="language-plaintext highlighter-rouge">1</code> or <code class="language-plaintext highlighter-rouge">0</code>. If the value is <code class="language-plaintext highlighter-rouge">1</code>, write the page back to the disk, then, clear that page in the RAM and replace it with the needed new page. Otherwise, clear and replace the needed new page.s</p> <h4 id="virtual-memory-with-paging">Virtual Memory with Paging</h4> <p>Abstraction: Do we have any guarantees on two concurrent threads writing to the same memory?</p> <ul> <li>No, we don’t have any guarantees regarding concurrent access.</li> </ul> <p>Performance: Do we get average latency close to RAM latency?</p> <ul> <li>Yes. LRU strategy should give us the average latency that is close to RAM.</li> </ul> <p>Fault-Tolerance: What happens on failure? Do we have any guarantees about the state that is on the disk?</p> <ul> <li>Depends on the data. If the fault happens in the disk, there might be only one page lost. However, if the electricity is running out, all the data stored in the RAM will lose.</li> </ul> <h4 id="interpreters-abstraction">Interpreters Abstraction</h4> <p>Examples of interpreters</p> <h4 id="communication-links">Communication links</h4> <p>API: <code class="language-plaintext highlighter-rouge">SEND(linkName, ourgoingMessageBuffer)</code>, <code class="language-plaintext highlighter-rouge">RECEIVE(linkName, incomingMessageBuffer)</code></p> <p>Examples of Communication Links</p> <p><strong>Other useful abstractions</strong></p> <p>Sychornization, data processing</p>]]></content><author><name>Ying Liu</name></author><category term="study"/><category term="ucph"/><category term="acs"/><summary type="html"><![CDATA[Basic concepts of computer systems.]]></summary></entry><entry><title type="html">Tivoli Firework</title><link href="https://liuying-1.github.io/blog/2022/tivoli-firework/" rel="alternate" type="text/html" title="Tivoli Firework"/><published>2022-12-27T16:00:56+00:00</published><updated>2022-12-27T16:00:56+00:00</updated><id>https://liuying-1.github.io/blog/2022/tivoli-firework</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/tivoli-firework/"><![CDATA[<h3 id="tivolis-firework">Tivoli’s Firework</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/kRDMWnQ.jpeg" alt="2831691531627_.pic" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <p>To “celebrate” Jianxiang Yu’s leaving, accompany Xuanlang Zhao, we invited them to <a href="https://www.tivoli.dk/?gclid=CjwKCAiAzKqdBhAnEiwAePEjkkNCCLulvpIQH-o8EmAQPiKdGUaNTz9pCCoCZBSeOKtVtuDSdX3NWhoCLkcQAvD_BwE">Tivoli</a> yesterday.</p> <p>We experienced all the roller coasters, including Demon, the most exciting one! Additionally, we also took the flying chairs and a lot of other exciting things.</p> <p>However, I still feel afraid to try the golden tower. Next time, I will definitely take it with Runfei Wu.</p> <p>In the end, we witnessed a marvelous firework show set off by Tivoli.</p>]]></content><author><name></name></author><category term="daily-life"/><category term="fun"/><summary type="html"><![CDATA[To accompany Jianxiang Yu, we went to the second oldest theme park worldwide, Tivoli in Denmark yesterday.]]></summary></entry><entry><title type="html">Royal Guardian</title><link href="https://liuying-1.github.io/blog/2022/royal-gardian/" rel="alternate" type="text/html" title="Royal Guardian"/><published>2022-12-26T02:22:35+00:00</published><updated>2022-12-26T02:22:35+00:00</updated><id>https://liuying-1.github.io/blog/2022/royal-gardian</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/royal-gardian/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/92CKp3h.jpeg" alt="2821691531541_.pic" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <p>My friend <b>Jianxiang Yu</b> came to visit me during Christmas. <b>Runfei Wu</b> and I brought him to visit a lot of attractions in Copenhagen on the first day, including the <b>Little Mermaid</b>, <b>Nyhavn</b>, <b>Kongens Nytorv</b> and <b>Grundtvigs Kirke</b>. In the evening, we had dinner with danish neighbors.</p>]]></content><author><name></name></author><category term="daily-life"/><category term="fun"/><summary type="html"><![CDATA[The shift of the royal guardian in Marmorkirken.]]></summary></entry><entry><title type="html">Swan Nearby</title><link href="https://liuying-1.github.io/blog/2022/swan-nearby/" rel="alternate" type="text/html" title="Swan Nearby"/><published>2022-12-24T01:51:45+00:00</published><updated>2022-12-24T01:51:45+00:00</updated><id>https://liuying-1.github.io/blog/2022/swan-nearby</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/swan-nearby/"><![CDATA[<p>Several days ago, there was great heavy snow in Copenhagen leading to most of the lakes being frozen.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/lkAiLks.jpeg" alt="2811691531400_.pic_hd" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <p>This photo was taken in the canal which is close to the KUA on my way to Rema 1000.</p>]]></content><author><name></name></author><category term="daily-life"/><category term="fun"/><summary type="html"><![CDATA[A record to keep this swan in my memory.]]></summary></entry><entry><title type="html">Chef First Time</title><link href="https://liuying-1.github.io/blog/2022/chief-first-time/" rel="alternate" type="text/html" title="Chef First Time"/><published>2022-12-24T00:17:11+00:00</published><updated>2022-12-24T00:17:11+00:00</updated><id>https://liuying-1.github.io/blog/2022/chief-first-time</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/chief-first-time/"><![CDATA[<div class="row mt-3 mb-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/SbVOyiT.jpeg" alt="2801691531302_.pic_hd" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <h1 id="being-the-chef">Being the Chef</h1> <p>I would say that was sort of my first time cooking for so many people. I have tried many dishes and the results seem to be successful. For dinner, I have cooked <u>spicy cauliflower</u>, <u>soy mushroom</u>, <u>green pepper pork</u> and <u>potato slice</u>.</p> <p>I appreciate the tietgenkolleigiet can offer me such precious opportunities to live here and have an excellent experience of socializing with my danish family!</p> <p>If possible, I would like to continue living here with my danish family!</p>]]></content><author><name></name></author><category term="daily-life"/><category term="fun"/><summary type="html"><![CDATA[This is my first time being the chef to cook for my danish family!]]></summary></entry><entry><title type="html">Travel to Malmö</title><link href="https://liuying-1.github.io/blog/2022/travel-to-malmo/" rel="alternate" type="text/html" title="Travel to Malmö"/><published>2022-12-23T17:07:52+00:00</published><updated>2022-12-23T17:07:52+00:00</updated><id>https://liuying-1.github.io/blog/2022/travel-to-malmo</id><content type="html" xml:base="https://liuying-1.github.io/blog/2022/travel-to-malmo/"><![CDATA[<h3 id="travel-to-malmö">Travel to Malmö</h3> <p>I would like to say this trip was pretty good as I spent the cozy day and bought what I extremely wanted in Malmö. Additionally, I ate the Chinese Crispy Chicken at a super cheap and reasonable price which is impossible in Copenhagen. It is so good!!!</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/s9rTpME.jpeg" alt="IMG_1826" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> <p>Below is the view I took by the coast of the sea in Malmö.</p> <div align="center"><div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="https://i.imgur.com/q5EjozM.jpeg" alt="128611682423844_.pic_hd" class="img-fluid rounded z-depth-1" data-zoomable=""/> </div> </div> </div>]]></content><author><name></name></author><category term="daily-life"/><category term="fun"/><summary type="html"><![CDATA[This is the final version of the image preprocessing with the limitation that cannot automatically crop the image in the center. However, it can work properly in normal situations. Also, this blog is used to record my trip to Malmö, Sweden with Xuanlang.]]></summary></entry></feed>